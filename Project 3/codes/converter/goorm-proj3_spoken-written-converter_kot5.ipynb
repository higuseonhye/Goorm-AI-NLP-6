{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMwgKq3wMK7mM8xM17TA4xF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"d8b83896332543c1a064785accc109df":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f823b505f2014bc5b0cea1db410b11a0","IPY_MODEL_7c8dc718d1ec45f5b6623d182cc88ed6","IPY_MODEL_f6c4925b7d53497688fa6f4986250aa7","IPY_MODEL_542a2882351d49c8bb7a25a9303e8200","IPY_MODEL_6319dafbac904938bb53f4a7ab5fa18d"],"layout":"IPY_MODEL_f14424f648c1417081311631c55f84ed"}},"f823b505f2014bc5b0cea1db410b11a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06da1e9247374f2ca3b665c7a855ccd7","placeholder":"​","style":"IPY_MODEL_fbedb9b37e8e4595be15ed753e5e537f","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"7c8dc718d1ec45f5b6623d182cc88ed6":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_9c7d8f112d3e4c6ba82a9d5faf43d60a","placeholder":"​","style":"IPY_MODEL_0438532704f243d18e8a64a6e2dff98e","value":""}},"f6c4925b7d53497688fa6f4986250aa7":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_ea47205ee4e84f78b710d04b2931a997","style":"IPY_MODEL_5287362c55554d7782072f30a277504c","value":true}},"542a2882351d49c8bb7a25a9303e8200":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_c6a329efa1684d8db33a53f273ed82ca","style":"IPY_MODEL_6a00e294a58e4382b7c15624f7131b3f","tooltip":""}},"6319dafbac904938bb53f4a7ab5fa18d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45296d591a95438a88c230f60781487e","placeholder":"​","style":"IPY_MODEL_ef10b65f26f04106a0818d67dcdd805b","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"f14424f648c1417081311631c55f84ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"06da1e9247374f2ca3b665c7a855ccd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbedb9b37e8e4595be15ed753e5e537f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c7d8f112d3e4c6ba82a9d5faf43d60a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0438532704f243d18e8a64a6e2dff98e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea47205ee4e84f78b710d04b2931a997":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5287362c55554d7782072f30a277504c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6a329efa1684d8db33a53f273ed82ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a00e294a58e4382b7c15624f7131b3f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"45296d591a95438a88c230f60781487e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef10b65f26f04106a0818d67dcdd805b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9abed31f560248269e4d99f7b8342775":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_247dfa08ac854225be6ffbaa37cfa7b9","IPY_MODEL_3a2dd67492834c7f89c1ff67ac35332c","IPY_MODEL_89f85894b1ca4690a50e97a84fd14719"],"layout":"IPY_MODEL_82b35c7e88774a569c08aaed2fdfe1dc"}},"247dfa08ac854225be6ffbaa37cfa7b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d845bbf8f346a9a4de6148d56e8db5","placeholder":"​","style":"IPY_MODEL_330c31b5ce5b470692248a0bbdb907b2","value":"Downloading (…)okenizer_config.json: 100%"}},"3a2dd67492834c7f89c1ff67ac35332c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa8fe1558099435a898bfee2e42dbff4","max":2403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5bb6e4bdd25f4e03a27188615d52e6d3","value":2403}},"89f85894b1ca4690a50e97a84fd14719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d9bee437d7844c6be3a22b544bfe661","placeholder":"​","style":"IPY_MODEL_21f57c6b29ed42aea6c413011a611cd3","value":" 2.40k/2.40k [00:00&lt;00:00, 145kB/s]"}},"82b35c7e88774a569c08aaed2fdfe1dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d845bbf8f346a9a4de6148d56e8db5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"330c31b5ce5b470692248a0bbdb907b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa8fe1558099435a898bfee2e42dbff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb6e4bdd25f4e03a27188615d52e6d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d9bee437d7844c6be3a22b544bfe661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21f57c6b29ed42aea6c413011a611cd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf4f9d1ed6384006908b830c88ec847f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec0b0710418e4cdabcc91380dc5dd9b6","IPY_MODEL_1985604135c94e4dbd79197500513e3d","IPY_MODEL_87098abf2dd54f4399842585d417bbb2"],"layout":"IPY_MODEL_91cb1dd24ab347959f57bd6e6f8ddee2"}},"ec0b0710418e4cdabcc91380dc5dd9b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee5d0ed5fdaf448197abd54024529856","placeholder":"​","style":"IPY_MODEL_75fb30c127da4ec1b6af96eea5ca704c","value":"Downloading (…)/main/tokenizer.json: 100%"}},"1985604135c94e4dbd79197500513e3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba2c86f89a074e7caa439bd913ff5017","max":2919674,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52291aaa39d74d0c847932f2be2c29c8","value":2919674}},"87098abf2dd54f4399842585d417bbb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_196b2272c07d4c17ab6c4c86aa6a5d8a","placeholder":"​","style":"IPY_MODEL_a7702ee5cc9f4fd0880ded61fec37af1","value":" 2.92M/2.92M [00:00&lt;00:00, 6.71MB/s]"}},"91cb1dd24ab347959f57bd6e6f8ddee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee5d0ed5fdaf448197abd54024529856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75fb30c127da4ec1b6af96eea5ca704c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba2c86f89a074e7caa439bd913ff5017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52291aaa39d74d0c847932f2be2c29c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"196b2272c07d4c17ab6c4c86aa6a5d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7702ee5cc9f4fd0880ded61fec37af1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53175721c1b8446da30a8bb712e44678":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b5fcfd8e77848cdb97cd8047c0e8192","IPY_MODEL_3ca1dc5282d143c794c17f1f3b31fd64","IPY_MODEL_4a7b0d0321ba4880a5aeda59b7f05acf"],"layout":"IPY_MODEL_54f8676cef634695967ea74f26003347"}},"3b5fcfd8e77848cdb97cd8047c0e8192":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d253ab6162044c5ac7a368846f2b6b5","placeholder":"​","style":"IPY_MODEL_39c6669ffbbe471b8a256d5c7d896936","value":"Downloading (…)cial_tokens_map.json: 100%"}},"3ca1dc5282d143c794c17f1f3b31fd64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_243920a8bcdb4527b402726bdd7663db","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67428da251fc438aadbe98324b7c3e7e","value":2201}},"4a7b0d0321ba4880a5aeda59b7f05acf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56ccd04348ac4692b7b343ae6775c72b","placeholder":"​","style":"IPY_MODEL_9ae01a3f52ca4824a99f52d4418e181d","value":" 2.20k/2.20k [00:00&lt;00:00, 145kB/s]"}},"54f8676cef634695967ea74f26003347":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d253ab6162044c5ac7a368846f2b6b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39c6669ffbbe471b8a256d5c7d896936":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"243920a8bcdb4527b402726bdd7663db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67428da251fc438aadbe98324b7c3e7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56ccd04348ac4692b7b343ae6775c72b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae01a3f52ca4824a99f52d4418e181d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5045cd4ff2144079a7d3a048eb7b145":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36b0db75e7b443a1a525de3ca7957799","IPY_MODEL_80f9d15969434004903a9da81b00b30b","IPY_MODEL_208674731b4740c8ac19326d520ce03b"],"layout":"IPY_MODEL_7e810ff9ba5e4b129c1eaaadd4bea8f1"}},"36b0db75e7b443a1a525de3ca7957799":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d89d354fbfcb4c629c5b1bb0235a769d","placeholder":"​","style":"IPY_MODEL_3a9025de651b4e6aa1bad1506ea52b0c","value":"100%"}},"80f9d15969434004903a9da81b00b30b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b36065802c7244eaa3e0bdd53fc1a34a","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90865089cac34cfdb3c37b4aa83f717b","value":12}},"208674731b4740c8ac19326d520ce03b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2dd054b6ee64428981ef9282945ed3b","placeholder":"​","style":"IPY_MODEL_54c0d592d9f44fc08f23ea3e1710ae48","value":" 12/12 [00:00&lt;00:00, 17.60ba/s]"}},"7e810ff9ba5e4b129c1eaaadd4bea8f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d89d354fbfcb4c629c5b1bb0235a769d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a9025de651b4e6aa1bad1506ea52b0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b36065802c7244eaa3e0bdd53fc1a34a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90865089cac34cfdb3c37b4aa83f717b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2dd054b6ee64428981ef9282945ed3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54c0d592d9f44fc08f23ea3e1710ae48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c13f46a487f44a08bd8cf653fd3832d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2037015fedfa459da893a75e047492d4","IPY_MODEL_ea0cf5d34b7e49d788c71e76933bb773","IPY_MODEL_41fa21e15eb34025af797dc7a0f95fcf"],"layout":"IPY_MODEL_aa47704343524bb593501e93ca01bc0d"}},"2037015fedfa459da893a75e047492d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef2f07abdf84a6da91c09b64adf4de9","placeholder":"​","style":"IPY_MODEL_80415c5069cc4db69b7a0863190d9168","value":"100%"}},"ea0cf5d34b7e49d788c71e76933bb773":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_052e2f3c3e0b45d8b7947dd8c760fe4c","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_696c0d3e53a04cb59bc07b5507143af2","value":3}},"41fa21e15eb34025af797dc7a0f95fcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17ff2187b18a44369a56fec2d5a79c51","placeholder":"​","style":"IPY_MODEL_6e16cd5692ed4987aa8f434460a9d226","value":" 3/3 [00:00&lt;00:00, 15.83ba/s]"}},"aa47704343524bb593501e93ca01bc0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fef2f07abdf84a6da91c09b64adf4de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80415c5069cc4db69b7a0863190d9168":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"052e2f3c3e0b45d8b7947dd8c760fe4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"696c0d3e53a04cb59bc07b5507143af2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17ff2187b18a44369a56fec2d5a79c51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e16cd5692ed4987aa8f434460a9d226":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57016c2ccfda4529ada3994ebe248d06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b0660b217b04dd2b32088e898dc572b","IPY_MODEL_acb3cdd37ad0495d846d5b831dcbef9b","IPY_MODEL_5152e135092f46ef8e8593db76cd9f5a"],"layout":"IPY_MODEL_7585fdc659954a90b03b75a3d1a580a7"}},"1b0660b217b04dd2b32088e898dc572b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4916a758e9dd4b35b5b64ad00a8b079e","placeholder":"​","style":"IPY_MODEL_a42715db2a414eada46a5148dc1f7d8a","value":"Downloading (…)lve/main/config.json: 100%"}},"acb3cdd37ad0495d846d5b831dcbef9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_decfcfee765542f2820017eef0a44c48","max":790,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48806355a58d44aba6253795244628a8","value":790}},"5152e135092f46ef8e8593db76cd9f5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8529e44834144b638a32b2e9cd60bc03","placeholder":"​","style":"IPY_MODEL_51fbe29b94d04efabdc8e140cfdace05","value":" 790/790 [00:00&lt;00:00, 35.2kB/s]"}},"7585fdc659954a90b03b75a3d1a580a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4916a758e9dd4b35b5b64ad00a8b079e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a42715db2a414eada46a5148dc1f7d8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"decfcfee765542f2820017eef0a44c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48806355a58d44aba6253795244628a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8529e44834144b638a32b2e9cd60bc03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51fbe29b94d04efabdc8e140cfdace05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"587332e24c834a7dac2b95b80c99701e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8914834a8cb842adba7b72d4a4362c88","IPY_MODEL_c1415c6b982a4a75976395977a9d9cf9","IPY_MODEL_7be6fbbb37e24bbe81eb2d96c47e5068"],"layout":"IPY_MODEL_03f00e13de4043879d38fb09c6aace97"}},"8914834a8cb842adba7b72d4a4362c88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_065a18a952484d828570d60ccc47c549","placeholder":"​","style":"IPY_MODEL_416cf29f759e4bca9325d0a762009ae2","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"c1415c6b982a4a75976395977a9d9cf9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf8bd9e6f1dd4f3ca551392247e27bcc","max":1102407757,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9c8ee1cf46447e7bd44ba68500a293d","value":1102407757}},"7be6fbbb37e24bbe81eb2d96c47e5068":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98f19c89a2584af8b31e15dd1c549405","placeholder":"​","style":"IPY_MODEL_298b896b3e5f4e3297bb1a242ea47215","value":" 1.10G/1.10G [00:43&lt;00:00, 14.9MB/s]"}},"03f00e13de4043879d38fb09c6aace97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"065a18a952484d828570d60ccc47c549":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416cf29f759e4bca9325d0a762009ae2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf8bd9e6f1dd4f3ca551392247e27bcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9c8ee1cf46447e7bd44ba68500a293d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98f19c89a2584af8b31e15dd1c549405":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"298b896b3e5f4e3297bb1a242ea47215":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fef29b7a486445591cd645d99b6d0b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef59189482cf41df877f32f501567c22","IPY_MODEL_573c5895d03c415784a495ab8ff7251b","IPY_MODEL_eefb318e603a49e884f164244a04d742"],"layout":"IPY_MODEL_2e25355c18194e23af29cde871a1e0d3"}},"ef59189482cf41df877f32f501567c22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5896750354340599cb6a2c6e0e93a5c","placeholder":"​","style":"IPY_MODEL_3498440190f540e0ad81ae1353e47544","value":"Upload 1 LFS files: 100%"}},"573c5895d03c415784a495ab8ff7251b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ee18ca58d624731b6da997d9dd5e5ae","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab0a4e0b156c4b16905f6b5663a3ee74","value":1}},"eefb318e603a49e884f164244a04d742":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_194310b9c031461c9813d1c344b7a1aa","placeholder":"​","style":"IPY_MODEL_41aecfde5921413886162915a2c302b0","value":" 1/1 [00:30&lt;00:00, 30.39s/it]"}},"2e25355c18194e23af29cde871a1e0d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5896750354340599cb6a2c6e0e93a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3498440190f540e0ad81ae1353e47544":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ee18ca58d624731b6da997d9dd5e5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab0a4e0b156c4b16905f6b5663a3ee74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"194310b9c031461c9813d1c344b7a1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41aecfde5921413886162915a2c302b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35f2de1324344d07999cad2f947001df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a26cf79998e146cead0a23dc05384456","IPY_MODEL_0fd33191246948ab8d07d14b3d15b590","IPY_MODEL_cc8b0117f80141be8082a5d47fb66a2e"],"layout":"IPY_MODEL_4e95a53ce46e4d018f146ec064e0fce5"}},"a26cf79998e146cead0a23dc05384456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b69f5de55e14ffcae080b585940df21","placeholder":"​","style":"IPY_MODEL_62c97871fb58436cb43b0d39cf3ff659","value":"pytorch_model.bin: 100%"}},"0fd33191246948ab8d07d14b3d15b590":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6649e23c81204a2e813062cdeeb0ef07","max":1102414005,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17c7c805c04f4360b2783b0aa5cd0097","value":1102414005}},"cc8b0117f80141be8082a5d47fb66a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_868444fc85454a59b32c0f4ccee7fffb","placeholder":"​","style":"IPY_MODEL_afc60c1e71344052a46902a7a74e6e68","value":" 1.10G/1.10G [00:30&lt;00:00, 47.4MB/s]"}},"4e95a53ce46e4d018f146ec064e0fce5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b69f5de55e14ffcae080b585940df21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62c97871fb58436cb43b0d39cf3ff659":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6649e23c81204a2e813062cdeeb0ef07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c7c805c04f4360b2783b0aa5cd0097":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"868444fc85454a59b32c0f4ccee7fffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afc60c1e71344052a46902a7a74e6e68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb41683683154391b48f12ac18f07c4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9d48ba68d8b48d2ad7f978d6a536012","IPY_MODEL_55025c38198e40589b00827024db51a7","IPY_MODEL_446f2b7f7e3c4fa0b7a582a77c5cc712"],"layout":"IPY_MODEL_dd784791cf284e0f9d1687c88e981879"}},"b9d48ba68d8b48d2ad7f978d6a536012":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9dde4aafaf4d55b42babea1dd5026f","placeholder":"​","style":"IPY_MODEL_0c78a9ba12f4435ebda329987b157d79","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"55025c38198e40589b00827024db51a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5835194205504b26a8306f9b2ad87e6a","max":1102414005,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bce6c60058742ce867cfbaa4a9189f1","value":1102414005}},"446f2b7f7e3c4fa0b7a582a77c5cc712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f1b6ba135c4aa1a9dc21f21f8744af","placeholder":"​","style":"IPY_MODEL_41931f0cf8c84dc281a0524facdae30d","value":" 1.10G/1.10G [02:57&lt;00:00, 16.5MB/s]"}},"dd784791cf284e0f9d1687c88e981879":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9dde4aafaf4d55b42babea1dd5026f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c78a9ba12f4435ebda329987b157d79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5835194205504b26a8306f9b2ad87e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bce6c60058742ce867cfbaa4a9189f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5f1b6ba135c4aa1a9dc21f21f8744af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41931f0cf8c84dc281a0524facdae30d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eb421ae8dd14f2da7cb946c234de8d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f560032d7eb04c33b202a89c297330b1","IPY_MODEL_d6f7d98fc3914af386c395d77b2b99d7","IPY_MODEL_39a23a088e734e4c8c0f39bf29d97cbb"],"layout":"IPY_MODEL_8fd2efca674a49b2bcb3fd75bc0e1765"}},"f560032d7eb04c33b202a89c297330b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3762b9d09ad24384a7b82e7ee66eb351","placeholder":"​","style":"IPY_MODEL_3a33129f1c15423184490e27726da213","value":"Downloading (…)neration_config.json: 100%"}},"d6f7d98fc3914af386c395d77b2b99d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a1c07c3ca7a48fcb245426417ca5f80","max":163,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef62835a442e4bebbc549be8d1f4a2dd","value":163}},"39a23a088e734e4c8c0f39bf29d97cbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f442c518bfc6477689b6f5b8d48ef8d2","placeholder":"​","style":"IPY_MODEL_62f2d8bba90949d1afb48a6eb178998c","value":" 163/163 [00:00&lt;00:00, 6.51kB/s]"}},"8fd2efca674a49b2bcb3fd75bc0e1765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3762b9d09ad24384a7b82e7ee66eb351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a33129f1c15423184490e27726da213":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a1c07c3ca7a48fcb245426417ca5f80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef62835a442e4bebbc549be8d1f4a2dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f442c518bfc6477689b6f5b8d48ef8d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62f2d8bba90949d1afb48a6eb178998c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 📖 References\n","\n","- https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb\n","- https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb\n","- https://huggingface.co/gogamza/kobart-base-v2"],"metadata":{"id":"bEJn20VNO-mH"}},{"cell_type":"markdown","source":["# 0️⃣ Prerequisite"],"metadata":{"id":"aLK88AVoI6sV"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYsAAAE5CAYAAABh4gz1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACakSURBVHhe7d0LkBTV3ffxv1zlDgJyEcQruuCFGFAkEhV9wZgKeOEF8dWXlOgj5nmIFCkpjYFXQcsIKUKFJxF8ykQsdZUAlpeYgIjy5tE3GqIgIt4CAkZQQC5yERbh9Xe2e+lteubM7M7szux+P1Vd03O6e26w5zfnnJ4+x/Tv3/+wAQCQRoPgFgCAlAgLAIAXYQEA8CIsAABehAUAwIuwAAB4ERYAAC/CAgDgRVgAALwICwCAF2EBAPAiLAAAXoQFAMCLsAAAeBEWAAAvwgIA4EVYAAC8CAsAgBdhAQDwIiwAAF6EBQDAi7AAAHgRFgAAL8ICAOBFWFRT165dbdq0aTZ58uSgpPrGjRtns2bNst69ewclAFC7junfv//hYD0vVOGNHTvWPvzwQ1cBVlf4eM2bNw9K0tu7d6/Nnj3bVq9eHZRkRyHQsmVLmzlzpn322WdB6REKi/Hjx9vu3bttypQpQWm5cFv79u2DkmTbtm2r9PgKi549e1brdQNALhVtWOTq8XyqExZJfI8nhAWAQkM3VBoKAlXsTZo0sTZt2riyyy+/3FXijzzyiFumTp3qbTmEtN+xxx7r1hs04KMHUDyosdLo1auXq9wVFgqJhg0b2pIlS1zLZsyYMW6ZNGmS60bKxCmnnOJCp1WrVnbyySe7MrWU1EIKw0dLnz593DYAKBR1fsxixYoVVXreHj16uOfZuHGjffzxx3bVVVe59/D73//edu3aFeyVeTeUgub222+3M844ww4dOmTr16+36dOn2zfffBPscQTdUAAKTdG2LBQC4bf7dEtVgkItgFtvvdUFwOOPP26LFy+2J554wk466SS75557bNiwYda6detg78xcffXVLgBWrVplf/3rX91jjRw5MtgKAIWNbqiIpk2b2ogRI1xLYc+ePTZnzpyKVsRrr71mDz74oBuU/t73vucq+0ypVXLZZZe5Vspjjz1mTz/9tL377rt20UUXuW0AUOhqrBsq024jWbRokc2bNy+4V1k+z4ZSCKgFsHLlSvf8+/fvD7aklq4bqkOHDjZq1Cg766yzbMOGDS58tm7d6rapZXLTTTdZSUmJa2089dRTFdvohgJQaPIeFknCClbSnUKaJNfhk0/nnHOO3XDDDbZ27Vr7wx/+cFT4aBxDYaL3VFpaau+8844rJywAFJqiC4uaEr7GTE+L1YB1Jr+zAIBiRFhUU7puqCRdunSxwYMH29lnn+1OoW3UqJEr11lRX3/9tQudv/zlL7QoABQUBrhr0KWXXmo///nP7dxzz7U333zT7r333oqztu666y575plnrF27dvbTn/7UdU8BQKGgZZFCrruhNNj9s5/9zI1T/Pa3v3X7Jwl/j6HTdx999FFbvnx5sAUAag8tCw9V6tHfbaRafF1QnTp1cpcO0emzqYJC1B316aefuu6ptm3bBqUAULvy0rLI9lt5KuHVWCWXj5dJSybbsQgfWhYAilmtdEMVg1yHhWjM4pprrrGysjL729/+5sYtPvnkE7dNQahTbfXjvY4dO9qrr77qTqcFgEJAWKSQbetIATB//nx3ocF0OBsKQDEiLAAAXgxwAwC8CAsAgBdhAQDwIiwAAF6EBQDAi7AAAHgRFgAAL8ICAOBFWAAAvAgLAIAXYQEA8CIsAABehAUAwIuwAAB4ERYAAC/CAgDgRVgAALwICwCAF2EBAPAiLAAAXoQFAMCLsAAAeBEWAAAvwgIA4EVYAAC8CAsAgBdhAQDwIiwAAF6EBQDAi7AAAHgRFgAAr4bdunW7J1jPi65du9qkSZNs6NChtmHDBtuyZYsrv/zyy23ixIl28skn25tvvunK8qF37942efJk69evn51zzjl200032ddff21r164N9vAbN25clY6L0msYPnx4pc8gn0aMGGETJkywHj165PXzBVA/FGTLQkEye/Zse+SRRxIXbdM+UQqladOmVewza9YsFxSZ0H7aPzxW4ZCN+HNHF4VENlTJ6zjdppLL5wOATOQlLKKV79SpU619+/bWvHlz901XZars1aLwWbFihY0ZM+aoZezYsbZkyZJgr3I333yztW7d2kpLS11LZt++fTZ69Ghr1apVsEcyvVY9nvbXcTpeZdkExmeffeZaSdHXqNcu77//vrvNhEKgb9++bl23up8k6fn0usvKymz79u3BXgCQO3kJi9WrV7vKNlqZRRdVzuvWrQv2rj5Vqi1btrRdu3bZe++95yrTjRs3WrNmzaxFixbBXskGDRrkgmz58uXuOIWQbrt3756yss5Eu3btXOX95ZdfBiXp6fNSsOo1P/nkk+5W9zNtKZSUlFjjxo3t888/D0oAIHfy2g0V795J6j7KBVXuu3fvdi2LXr16uUpelb1aC3v27An2SqZKfe/evS7gQvp2Hj5WVeg96jWE4ZVK9PPp2bOnzZgxw4XGyy+/7G51v2PHjm57um41lev4+PsAgFzJW1ioAot276hFoUpdg7z5CIwpU6a4xx81alTFN/S5c+faV199FeyRHX1L12Opou7Tp09Q6qeQGDx4sFtfvHixe02hsCsurPijLTDd6n50zCJpe5JBQevoww8/JCwA5EVewyLavSOvv/66u1WXSUgVsSpHVYZx4bakJWkAWIERdnWlq1wzoS4kjQPoscLxh0xo7ERjNHrP8XEVffMPWw96bepiir+vIUOGuH11G9+W1CWlz0Gf07Zt22zBggVBKQDk1jH9+/c/HKznlCoxVXiLFi2yefPmuTK1KNSyUEW5Zs2ainV9066O8LmSfPTRR3bCCSe401XVvaQQmz9/fkVFropblW30dapS1hjIzJkzXaWvfeLHJdFxOlVVFXd4bEjb1KWkrrhcffsPX7tCKP644WeioKvu5wsAeWtZqOJSJRY9q2fAgAHuVkGRS6rkwxbF+vXrK77B6/7zzz8f7JVs6dKllV6nKllV+Bogj1b26SgEVVnrOD2/zlTK9FiFUDhukWrRabLhZyjhMamCAgByLa9hoUosPKtHlZ4qPN+381zp3Lmzq1A1RqDusFTir7Mq38aPO+44V2mrdaKusGzo+dVCCMMuumisR62UuFNOOcXdKpjCLi0AyKe8dUP5RLukwoo5LNPgciY0rhAPn3h3j76Fa6A9VTdUJjLthkqnKt1QCtfx48e79Xi3lg/dUAByKa+nzmZLFbEq9qRv2UmL9q2JVgoA1HcFFRa5oG4gumYAILdqrRsKAFA86lzLAgCQe4QFAMCLsAAAeBEWAAAvwgIA4MXZUMhY23OvsBY9zrFjO51qzTqf7sr2bf7Ivv78n7br/f+2rz4sv1AkgLqHsIBXqzO+Z10G/7s1ads5KEl2YMdm27T4t/bVB68FJQDqCsICaXX+NiQ6XHCtWz+w83Pb9rf5tmf9ym9bEx+7smM7nfZta+Nca99/uDVp08mVbf12n80v/c6tA6gbCAukFA2KTYt+a9veTD9fRvvzr7UuQ/7drW99Y4Ft/raVAaBuqNGwaNiwoV199dU2cOBANzf2oUOH7IsvvrCFCxfaW2+95fZJmptCs+298cYb7lLk+/fvdxfl00UBoxfICy+6p0uLc+G86lPXU48RU936xw//W0VLonHbztb5f/zEmnU+zd3ft/lj14oo27HZ3VdL47R/e9itr583iS4poI6o0bOhRo4c6aYAffvtt12F/+tf/9pdOfbGG2+0M844I9jryIxyulig5oZYtmyZXXjhhXbdddcFeyDfugz5D3erFkU0KE69eY61OfMiN36hResq0zbRvjpGNM4BoG6osbDQxEDnnXeemyf60UcfdZfb1iRIai0cc8wxdsEFFwR7Vqb5HP74xz/aP//5TxcomrK0vhs2bFjiHB0qGzp0aHCv6nTWk8Yf3BhFpOtJlX+jZq3cmMUHs653i9ZVFg0GHaNjFSZqoQAofjUWFt26dbOmTZu6aU6jFBjqPnrssceCEqSjoFAg3HHHHZUCQ+sq03Yt1aEBa9FgdlRY/ulzD7puJy1aF51OGxUe2/qMi9wtgOJWY2GhmehEYw7Z0DjHZZddZieddJJt2rQpcea4+uSll16yDRs22IknnlgRGGFQqEzbtE91hBW/Wg1Ra6YPtXenDqoYn4hqeGzLYK1ceOyxncpn9QNQ3GrtF9zhvNXhPNOagyKkyk/Toar84YcfdoPemkK0tLQ02KP+0njO9OnTKwVGNCi0TftURzh4HY5VpNLg24A48X/e69bjZ0qFx4Y/3gNQ3GosLHbu3OluW7Ys/wYazoqXNM90dIBby6233mq/+tWvbOvWrcEe9Vs8MHIZFJnSgPZptzzswmD7ykX2xbK5wRYAdVGNhcW6dets9+7dVlJS4rqWqkOn3B5//PHu9NtQmzZtrEmTJhWhVNdFAyPXQaHTYUWnwaYS/qJbQfGvYNwiKjw2fCwAxa3GwkKtgldeecUNdP/kJz+x0047zf02YsCAAa7bac+ePcGefpoytWPHjnb99de7x1AA6fcbhw8fthUrVgR71X1hYOS6RaFrPUk4oJ2kdXCWky7vkSQ8NnwsAMWt4beV9z3Bet7p9Nddu3bZ+eef78Ys9JsLVfbvvvtuxQ/uevfu7U6zXb58uW3ZsiU4sjKdUdWgQQPr16+fXXHFFda/f387cOCAPf300/UqLES/U9GSSw2PbeXCoGmHE1P+avuL/zvXLYcPHghKKut+7WQ36K19DmzbGJQCKFZc7gOJev601P3WItVlPs6atNTd6uyouPCyH/qtxYe/GRWUAihmtXY2FArbpkX/6W5V6acbu4jTvuH1ocLHAFD8aFkgpeiFBD/7tuL/8s2Fbj0VLiQI1F2EBdKqdInyHZu/DYH5tnf9OxW/o1BLonmPc77dZ3jFfBcEBVD3EBbwcpMfDfmPivkqUtEYhbqeuNIsUPcQFsiYQkPXeiqfVvXI7yjctKof/DchAdRheQmL+++/P1hDIbn77ruDNQDIDi0LAIAXp84CALwICwCAF2EBAPAiLAAAXoQFAMCLsAAAeBEWAAAvwgIA4EVYAAC8CAsAgFedvdyHpmcdO3asm987lfXr19uUKVOCe+WqehwA1GV5C4uGDRvayJEj7YILLrAWLVrY4cOHbffu3fb3v//dzZX9zTff2OTJk91821H79u2zN954o2JO7nCfRYsWuTLR/N3Dhw93c0/Pnj3bVq9e7cqjwkpfjzdz5kz77LPPgi1VFz6vHouwAFCf5K0b6qabbrJBgwZZs2bNbPPmzbZt2zYXGpdccomrcKN27Nhha9eutU2bNlmTJk3s4osvtjFjxgRbC8/27duDNQCoH/ISFiUlJe6bvVoPzz33nP3iF7+wO++80/70pz+5b/qnnHKKNW3aNNjb7JNPPnGXNdd+L7zwgjvu9NNPd0t1tW/f3qZOnWqPPPLIUcu0adOsa9euwZ4AgFTyEhYKA7Uodu7caStWrAhKzZ599lm7/fbb7YEHHnBdTEkUHOpeatSokWtlVJW6psaNG+daKKmWiRMn5qR7CgDquryMWYwYMcKGDBniup40XtCrVy/X9dS4cWO3PSy/+eab3XiEAmXWrFmutXHjjTfa+eefb7t27XJlo0ePzmrMQi2F8ePHuxZFpvT8CxYsqNJxeo0AUNfVSFh07tzZBg8ebG3atLHjjz/+qLCIO3jwoL366qtWWlpa5QFuAEDu5KUbas+ePa7Cb9CggWstvPXWW/bLX/7S3n777WCPysIBbi2rVq2y3/3udy4ockFhkzReoUBLorEWtRZ0XFy6bQBQl+UlLFTpayC7devWduGFFwal5afTJgkHuLWoxbFy5cpgS3nwSLdu3SqOVwtFQaRtW7dudWVx6o4KB7AVPNGxCnUfqeWjMQ0AgF9ewmLNmjX25ptvuvVLL73UVdo6I0mnzYoGvrVkQq2RAwcOuDOsNDB+3333uYpe3nnnHfv888/dely7du3cILsGsJcsWRKUllu6dKnt3bvX7ZOKur7irZEJEyak/bEeANRVeQkL0Q/vdNqsuphUKXfp0sWdAaUf5c2ZM6eixeCjiv2JJ55wv23Q42j8Q60WjWnoOVLR/tpPLQuNcUQNGjTIVfrpfi+hX2lHWyNaZsyY4UIGAOqbOnu5j1A4QB4XHTCP4nIfAHC0Oh8WAIDqy1s3FACg7iAsAABehAUAwIuwAAB4ERYAAC/CAgDgRVgAALwaduvW7Z5gvSjp+k6aulW/CL/rrrvcxEm6NlUm9OtuzWmha05legwA1Ee1/qO88GJ+6eaFCC9JHs6HIbrshi5Prkt3iC4LoktyvPjiixXXgko6TsJjdbmP2267zZYtW3bU9aN8v+QOH4PLowOoD2o9LMLLfae7fIYq/SuvvNJdzC9eOYdhkyosNJ/3Qw89lDgjnloW6cJCEy/NnTuXQABQ79XqmIUqc1XYSRf7AwAUjloLC31zV2th/vz5bhk2bFjawFB3kC4RHl4uPDoXRZ8+fQry8uF6T0mvSWVDhw4N7gFA4auVsFBFr/EAVfrq/tGi/n9VrtEQiNIYgS4RHl4uPDrGocmMqnr5cM3kN2rUqKMCqLr0XhQId9xxR6XA0LrKtF0LABSDGg0LVcaqlMP16FiA1sPKOtcVdzqaYyOcSS8+yK7Jk6KtmfiSampWeemll2zDhg124oknVgRGGBQq0zbtAwDFoCguUa7uqaSzmjQnRadOndx6rge4cyEeDhKuT58+vUotIQCoDUXxozxV5Oq2CrugwiVp8qJCojBQKIQtDIICQLEqirAIqaWgubzVIshUx44d3THxLiTNC55uDu5ciQYGQQGgWNVYN1SqrqRUysrK3FlS0e4hX7dStpK6oXLxOpOEg9wEBYBiVFTTqtZEWAAAjlZ0YeH71q/TaNNdOiSKsACAzBRVWAAAakdRDXADAGoHYQEA8CIsAABehAUAwCsvA9z3339/sIaquPvuu4M1ACgMnA0FAPCiGwoA4EVYAAC8CAsAgBdhAQDwIiwAAF6EBQDAi7AAAHgRFgAAL8ICAOBVq2Exbtw4mz17tpvUKFMjRoxwc2jrNluTJ092EyP17t07KKk5ek49t14DABSbvF3uQ5X5kCFDgntHrF+/3qZMmeLWFRaqRKNzWKusT58+bj1Kc1crWLS/HnfRokU2b968YGu5+Ex64TGrV69291VRd+zYsVJZnGbPGz9+vLVv3z4oOdq2bdts5syZiVO7Jr0nUdnYsWNty5YtFe8fAIpF3loWqsjHjBlTscyYMcNV3plSGESPVyWcqoKXMChUgWv/SZMm2b59+1wFrYo6Uzp+4sSJlZ47XPSYCgoAqG/qzJhFSUmJu3399dfdrSr95cuXW/PmzbMKi+pq166da9kcd9xxrpUybdo01202YcIE91oAoBjlLSzCsYVwiVaW6g5SWVJ3UyFTEDRr1sx2796d2AWl1o0CQvr27etuw1ZKti0rACgkeW9ZxLuT1F+vResrVqwI9jqaxiWiYaNuqKhwe1i+Zs0adztgwAB3q0pbFbYq6HTdV7mi5xs8eLCVlZW599y6dWs39hGGBwAUs7wPcCcNRIeSBoNVphZHquPSPW51B7i1vUePHsE9v3CwPnxeib6X8PH0WvV8DHADKFY1fjaUhJVsrsMiH3yvRxQKakHEz4CK4mwoAMWsVmfKy0dYhMenEm9t+GQSFnGpgrKmAg4Aci3vYZFtSyBdZa8Wyfvvv+8Ni3gAhXzdUEmyDYtwf43H6Ed4oVTlAFAMCu7UWVWk0QHx6FLo3TfqiurevbvptxgLFiwISsvpvsq1nUFvAMWmzvzOohDodNqNGze6X39fe+21QWm5iy66yJVre9JptwBQyGqsGyqdbLpmGLMAgJpXqwPcAIDiQDcUAMCLsAAAeBEWAAAvwgIA4EVYAAC8CAsAgBdhAQDwqtdhoctuaCY7/YgOAJBajf8oz/eLbk0elOpS3/H5KkKpjkm1v67RNHPmTLeuCYo0/Sq/rAaA1ArqF9z6pn/bbbfZsmXLEiv+YcOG2bPPPpvVtjiFlWbQi4aFrtmUKnDi4Xbo0CHbsWOHvfLKK/biiy8GpeV+8IMf2NChQ91jxC8kqMuGnHvuufbqq6/a448/HpQeoddx9tlnc0kQAAWpTndDKUR0Hajo9KyprtmkiYlSBY2uJ6U5tHXl2wcffNA2bdpkP/zhD+373/9+sEc5hYGo0m/RooVbjzrmmGPc5dM7dOgQlJTTbHrdunUL7gFA4SmasFBFropfLYho5a9FXU2pWhWamW7SpEmVLnU+ceLEKl/59eOPP7bnn3/eDhw4YCeddFJQalZSUuJC4K233rI2bdpYr169gi1H7N6921q2bGn9+vULSsqppdO0aVPbs2dPUJJM77158+bBvSNUphYNAORLUbUstm/fbvv27XMtgbDiLy0tdYHw3nvvBXtlT60NBZFaIpk4ePCgffPNN66CD333u991ZQqsnTt32nnnnRdsOUKvX+Ml0SBRC0QtkU8//dS+/vrroPRoCgoFwh133FEpMLSuMm3XAgD5UKthofEAnY0UTgbUrl07VwGrmycU7UqaOnWqG19Q5R62KkaNGuWO1zbdj1f6mhkv3BZd9Lx6PvF1Q0Wp9XDVVVdZs2bN7IMPPnBlqvBPO+00W7t2ra1bt85WrVplp556quteimrSpImtWbPGTjjhBNcSEYWKXsfKlSvd/VReeukl27Bhg5144okVgREGhcq0TfsAQD7U6gB3dLBZ3ULqzx89erTNnTs34/kmqkMh4zsbKunsLY1hKGBeeOEFd3/gwIF29dVX25NPPukeS0GgVs/LL79sf/7zn90+GuDWLHlPPPGE3XDDDS4cNNCtcr2ORx991B2T7rXEw0HC9enTp7vXBQD5UFBh4RNW7mpdRIWnwqZ7DM2/Hf+mn8lESHqNCoNwv1tuucWFwZw5cypaFqkmXNL4hlow6p4Kw0Kv80c/+pEb71BY/PjHP3bB8Y9//MO1bl577bW0Z0NFA0MICgA1oWjGLNTquOuuu9y0pOF4RbioTNu0T5wCRhW2xgvix2lQXBV0pmMVolNmdfrs4MGD3X0FkCruxYsXV3rshQsXui6rnj17uv2iNAiurqsrrrjCGjZs6IKiQYMGbvFRKCgcFBIEBYCaUmNhkeo0VrUSksYU4mMPXbp0cb9viP9+QVSmbdonToPJjRo1sqVLlwYlR2iMQoPj4fhBJtRaUOV++umn2/nnn2/f+c533FhEfIBd9w8fPuwGvuO07csvv3SvTRW+xjGyEQYGQQGgptRYWKhi1rf46LfvdEt8wFmD3m3btrVrr702KDlCZdoWHRgPqWLW2UuDBg0KSo5QGGkAPNvKWgPJu3btcmF31llnuVaLBrejNNCt13PGGWdY69atg9JyOkVWg+A6+0nBUxUKCYICQE0pqjm4a2PMAgBQZGEBAKgdRTPADQCoPYQFAMCLsAAAeBEWAACvvAxw33///cEaCsHdd98drAFA1XA2FADAi24oAIAXYQEA8CIsAABehAUAwIuwAAB4ERYAAC/CAgDgRVgAALzy8qM8zR43dOjQinmis7V161Z76qmn7O233w5KAAC1KS8ti1GjRlU5KERzVytsAACFIS8tC82hLZoetSqqe3ycpk+9+OKL7aGHHko7m15dVJX3Hs5IuHz5cps3b15QWplmHtR0srNmzQpKyo+77bbbbNmyZZWmxM2GHvf9999363379vXOgFhoevfubaNHj7a5c+e66X71XlJ9hknC95/NMUlGjBhhZ555pk2ZMiUoyZyO1Wev93Dddddl/e85btw4a9euXZWeG4WrzoRFdNrU+DSrmVaYVf1DjT53klTTvvqOW79+fdo/OP1Rax7wJCtWrHAVedJ7T/W8ZWVlNn/+fDdveTwsVAlqXvTmzZu7+3F6j5lULtGpcXXMu+++616fLFq0yFVwmYaF7/ML30/8tegzGT58uDVu3DgoqSyTaXolKRyzCYtU0wTHhf+WoVT/FtH9Mg0LPZb+zl588cWK95AuLFK95uhnTVjUTXUiLFRpSPifM36/JsIiF98Go7L9Zqg/UIlWKpLuvYd/+PEWRKpyn6TKMy6+T/x9hp+lVKdlkVQJhjL9/+CT9H6zCYu4MMR27dqV9fvWv3+TJk2sU6dOFRW578uGZBsWSeKPodfSp08fty0edCheRX82lP7A2rZtawsWLAhKzK2rTNsKmSpGBWPSkqrFkEv69tesWTNXwWRKFUH8tapyqY/0+en/WUlJifu/Nnv2bJswYYL7TLOh0Jk2bZoNHjzYVe6LFy92/ze0JFHlrAo4+m+gyvnAgQM2ceJEV3GrlZYptbCOO+644F45BY7eS8eOHYOScuFrjT639ou3chRUeh0ERd1R9GGh/+Q7duyw1atXByXm1lUW/wPIJ1Xu0T+g6JKuMtUftf6okpZMWxWiiktLNvTNd9++fda9e3dXAcXpPakCDENX76Nnz542Y8aMitdYWlpqAwcOrNinadOm7gSH6HG15eDBg7Zp06bgXu4NGjTI3Z588snuedQ1pM9Gn2kmwuBVKCggVNGrNaFv53ostUq0PemzVLePPvvo/xd9SQor8ky/bOg96G/l7LPPdkEQUlec3suWLVuCkiP2799/1HPr9aZrfaD41enfWWTzjbm60lX66boh0oWMvpUlVeJx2kffALVoXZV6+BiquFWBR4XfDkUVlCoqvc74c+k9xSsBVYQa2E4lrEiqU3noM/FVduE3+ejnFV2q8g0/G/qMFbIPPPCArVu3znU9RSvbTOjfV597qs9K/2/SbY9T0GTTslBI6QvGpEmT7IsvvnBdj9m+h1Q0lqR/h7B7FMWv6Mcs9Eeb1LevP4Swv1gVS6ZjFukGTPfu3esqqGgrRqLPVRvCz0DiZyjF37sCQZXPhx9+WGm/aLm+oaYas4j2R0t0YFMVTSGNWYRjB/F/L30m6Qa4Uw2Mh/QZKCiir03vQ6934cKFds0113jHLLR/pt/+Jfp/L/y3inf9RF93qr+LkD5niW7X+1J46DVnO8At4fOrW06Pk03LGIWv6MNCf/hXXnmlOyasFPTHpGPDAbdMwyIqXWUTl23I+PaPSzdQGX2v6gqJv+aqvPewQsh2gDsT+QqL+ONk8+9XSML3X1tfPIBUOBsqhWKobMJKfePGjRWtBFWaGkMIw8n33pOCK1ULStJ9sxTft/KaCouq/Jtny/dZiLqD0lX8et3pWhip/i0yee5MzoaSVI+V6hRi/W0ktWyiMn1uFI86+TuL+H/UQg2LpIo6yvcHp+Pj3U6iCiisaHv16pX43sMKIho0IR0/aNCgtJV+kngQJIlWTAqWjz76yL1GUeWkMY9Vq1a5+9UJi0IQBl9VWwnV+T+Y6eehvw11yS1duvSo16luKZ3QkOqLQyphdxZhUbfUmbBIpyrfrtMJK/GqHpeJXFV+qd57Jp9JUhD5vtH6WhY+YQUrqcJCn01V+vtV+VZ1nCCJ77OQfLUsfDL9/+Or2KsSeIRF3URY1CJf2OSiKZ/qvVe1ZZFJ66E6MgmLQpGLzyJXXwriMn1c/f+gZYFMEBa1qCrf2rKVSQsiHljVGbOQ6vxqt9jCwvdZ+C4d4mtZiK91kiSbEEr1PjK97EkcYVE31YuwKFS+lkVVuyAAINfyEhb6wVe6b1uZ2LBhg917773BPQBAbcrLL7j1C15V9lWl5u9zzz0X3AMA1La8tCwAAHVLnb42FAAgNwgLAIAXYQEA8CIsAABehAUAwIuwAAB4ERYAAC/CAgDgRVgAALwICwCAF2EBAPAiLAAAXoQFAMCLsAAAeBEWAAAvwgIA4EVYAAC8CAsAgBdhAQDwIiwAAF6EBQDAi7AAAHgRFgAAL8ICAOBFWAAAvAgLAIAXYQEA8CIsAABehAUAwIuwAAB4ERYAAC/CAgDgRVgAALwICwCAF2EBAPAiLAAAXoQFgERdu3a1qVOn2uWXXx6UlOvdu7dNmzbN3SJ7bXoPslNvmWONWrUPSvy07+k/mWsdBowKSmoeYQEgL8aNG+eW+kSV+VmTliYuJwy7M9jraCf/+DeJx/S6888uXArBMf379z8crAOo59RaGDt2rDVv3jwoqWzRokW2evVqGz16tM2dO9etpzJ58mR3O2XKFHdb34Th8K9nf+luQ6r8OwwYaeuf+rkd/GpbUFpOLYiTb5xh21f8xba+XhqUpi6vSbQsAFRQ5a/WwJgxY6y0tNTKyspsxYoV7r6WefPmBXump64rdWP16NHDRowYEZTCp1GL46xhs9bWtGOPoKRwEBYAjqLAGDVqlG3ZsqVijEKVfyYUFMOGDbP58+e7wBk4cOBR4x71QZN2Xd2SjS5XjLNv9u2y5ieU2LGdTw9Kj+h82S211jXVsFu3bvcE6wDqObUCJkyYYI0bN7YHHnjAnnvuOXvhhRfszDPPtOuvv9769Olja9ascbcrV650YRKlkLnkkkvsmWeesSVLltjatWttw4YNdsMNN1i/fv1s2bJlwZ51myr6DhcMt0bN29judW9Z23OG2Ck//o0df/Foa1PyfTu0f6/teGeRHTqwz+2vbqZTb55th8r22z//61b7Zu8u6zZ0ou1Zv9IO7v7SGjRtbu3OHWJb/988W196p+3fss4dV5MYswCQFbU04mMWCgkFiLqsZs2a5criFERDhgxJu09doYHuVj0vdOsHtn9WadwiPmahYDnpf02zrz5+o9J+0fLPl/5XrY9ZEBYAHN/gtmgMY+nSpda3b1/vAHd4JlRdD4Y4VfI9Rt5nm5fMsf3bNlr3a35hGxfeZ19v/shtTzfAnUohDHATFgASaYxi/Pjxtnz58koD20ktiyT1MSzCSn3vv9ZUtBLUyuhw4Qj75ImJLjB8YaHTaFt0Pyu4V+7g3p0Vx9cWBrgBIEe6X/t/KgWFqCWgsQa1MBQmqWibfninbqt3pw6qtOh4jXnUxsB2iJYFgESZtix0ptPw4cPdoHgm1JWlM6U0AF4fpWpZZNLiiI9/1CTCAkCi6nZDIVmqUEjqwgqpK+v47/9v+9fz023n6qVBac2iGwoACoCC46PfjXa/zYhf9kNjHmsf/WmtBYXQsgAAeNGyAAB4ERYAAC/CAgDgRVgAALwICwCAF2EBAPAiLAAAXoQFAMCLsAAAeBEWAAAvwgIA4EVYAAC8CAsAgBdhAQDwIiwAAF6EBQDAi7AAAHgRFgAAL8ICAOBFWAAA0iorK7P/D1K7umUJolBDAAAAAElFTkSuQmCC)"],"metadata":{"id":"JLTgv42uPHVn"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4T0Dfks1I1eo","executionInfo":{"status":"ok","timestamp":1675133806479,"user_tz":-540,"elapsed":21863,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"fc3e77c6-6347-4e9a-fb2d-ddfc01affba6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruWg5bfNJBCm","executionInfo":{"status":"ok","timestamp":1675133806480,"user_tz":-540,"elapsed":17,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"ce14c076-73d2-4089-fb55-a23a4d9332f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Jan 31 02:56:45 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/Study/Data Science/AI 자연어 처리 전문가 양성 과정 6기/Project 3')"],"metadata":{"id":"QQDvMpFtJHMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q datasets torchinfo transformers sacrebleu sentencepiece wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aqp5S07JXNG","executionInfo":{"status":"ok","timestamp":1675133823487,"user_tz":-540,"elapsed":15806,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"a7bdb9bc-a891-48fd-8bbc-636239fbc69b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict, load_dataset, load_metric\n","from easydict import EasyDict as edict\n","from sklearn.model_selection import train_test_split\n","from torchinfo import summary\n","from transformers import (\n","    AutoTokenizer,\n","    T5ForConditionalGeneration,\n","    DataCollatorForSeq2Seq,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    EarlyStoppingCallback,\n",")\n","\n","import numpy as np\n","import pandas as pd\n","import random\n","import sentencepiece\n","import torch"],"metadata":{"id":"KaqaaE_6JbY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Log in to your W&B account\n","import wandb\n","\n","wandb.login(key='eeef6909a6674c953c756358e614461bdced83c4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bh9vqJxqJY-7","executionInfo":{"status":"ok","timestamp":1675133834070,"user_tz":-540,"elapsed":3947,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"61951119-f0c7-4375-8944-2908464b0f68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303,"referenced_widgets":["d8b83896332543c1a064785accc109df","f823b505f2014bc5b0cea1db410b11a0","7c8dc718d1ec45f5b6623d182cc88ed6","f6c4925b7d53497688fa6f4986250aa7","542a2882351d49c8bb7a25a9303e8200","6319dafbac904938bb53f4a7ab5fa18d","f14424f648c1417081311631c55f84ed","06da1e9247374f2ca3b665c7a855ccd7","fbedb9b37e8e4595be15ed753e5e537f","9c7d8f112d3e4c6ba82a9d5faf43d60a","0438532704f243d18e8a64a6e2dff98e","ea47205ee4e84f78b710d04b2931a997","5287362c55554d7782072f30a277504c","c6a329efa1684d8db33a53f273ed82ca","6a00e294a58e4382b7c15624f7131b3f","45296d591a95438a88c230f60781487e","ef10b65f26f04106a0818d67dcdd805b"]},"id":"AHBWGNPBsP7m","executionInfo":{"status":"ok","timestamp":1675133834072,"user_tz":-540,"elapsed":13,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"ad13ee49-9ec3-4aa4-d1a0-2eb96b19b532"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid.\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["def seed_everthing(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everthing(42)"],"metadata":{"id":"BSLpJoDNMVh4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1️⃣ Loading the dataset"],"metadata":{"id":"TDq5TWYyJ4JW"}},{"cell_type":"code","source":["\"\"\"df_a = pd.read_csv('output/df_spoken-written_a.csv')\n","df_a.columns = ['id', 'spoken', 'written']\n","\n","df_b = pd.read_csv('output/df_spoken-written_b.csv')\n","df_b.columns = ['id', 'spoken', 'written']\n","\n","df = pd.concat([df_a, df_b])\"\"\""],"metadata":{"id":"SxxnATe0LmYX","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675133850924,"user_tz":-540,"elapsed":12,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"ea2b28a5-5320-40c2-970c-038ab6faa68d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"df_a = pd.read_csv('output/df_spoken-written_a.csv')\\ndf_a.columns = ['id', 'spoken', 'written']\\n\\ndf_b = pd.read_csv('output/df_spoken-written_b.csv')\\ndf_b.columns = ['id', 'spoken', 'written']\\n\\ndf = pd.concat([df_a, df_b])\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\"\"\"df_train, df_validation = train_test_split(df, test_size=0.2, random_state=42)\n","df_train.to_csv('input/df_spoken-written_train.csv', index=False)\n","df_validation.to_csv('input/df_spoken-written_validation.csv', index=False)\"\"\""],"metadata":{"id":"qw_Gnrx_LpRL","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675133850924,"user_tz":-540,"elapsed":10,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"befa97fb-2ef8-49a4-e6d3-84d557912b9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"df_train, df_validation = train_test_split(df, test_size=0.2, random_state=42)\\ndf_train.to_csv('input/df_spoken-written_train.csv', index=False)\\ndf_validation.to_csv('input/df_spoken-written_validation.csv', index=False)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df_train = pd.read_csv('input/df_spoken-written_train.csv')\n","df_validation = pd.read_csv('input/df_spoken-written_validation.csv')"],"metadata":{"id":"NmajqzsLQtP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds_train = Dataset.from_dict({'translation': df_train[['spoken', 'written']].to_dict('records')})\n","ds_validation = Dataset.from_dict({'translation': df_validation[['spoken', 'written']].to_dict('records')})"],"metadata":{"id":"N78HqE2RQPBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_datasets = DatasetDict({\n","    \"train\": ds_train,\n","    \"validation\": ds_validation})"],"metadata":{"id":"kR1YfVsvUdwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Number of Train Samples:\", len(raw_datasets['train']))\n","print(\"Number of Validation Samples:\", len(raw_datasets['validation']))\n","print(raw_datasets['train'][0])\n","print(raw_datasets['validation'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Up6fCf5sLgMc","executionInfo":{"status":"ok","timestamp":1675133854572,"user_tz":-540,"elapsed":5,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"0f0e72d5-ca48-4931-d9ed-0f99163a5ee3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Train Samples: 11012\n","Number of Validation Samples: 2754\n","{'translation': {'spoken': '차가 없어서 그러는데, 택시 외에 쇼핑센터로 가는 방법이 있나요?', 'written': '나는 차가 없지만 택시 외에 쇼핑 센터에 갈 수있는 방법이 있습니까?'}}\n","{'translation': {'spoken': '이 불고기 맛이 너무 환상적인데 어떻게 만드셨나요?', 'written': '이 불고기 맛은 매우 환상적입니다.어떻게 만들었습니까?'}}\n"]}]},{"cell_type":"code","source":["del df_train, df_validation\n","del ds_train, ds_validation\n","\n","import gc\n","gc.collect()"],"metadata":{"id":"zeFlPLaGVurF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675133856880,"user_tz":-540,"elapsed":4,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"6fc40d14-1bb2-4654-86f0-a38fa36a7d11"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# 2️⃣ Preprocessing the data"],"metadata":{"id":"nkazXujmMV-j"}},{"cell_type":"code","source":["model_checkpoint = 'lcw99/t5-base-korean-paraphrase'"],"metadata":{"id":"cMrUO0foMtZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"id":"KiPV6LwmL3Fx","executionInfo":{"status":"ok","timestamp":1675133867791,"user_tz":-540,"elapsed":3380,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["9abed31f560248269e4d99f7b8342775","247dfa08ac854225be6ffbaa37cfa7b9","3a2dd67492834c7f89c1ff67ac35332c","89f85894b1ca4690a50e97a84fd14719","82b35c7e88774a569c08aaed2fdfe1dc","e9d845bbf8f346a9a4de6148d56e8db5","330c31b5ce5b470692248a0bbdb907b2","aa8fe1558099435a898bfee2e42dbff4","5bb6e4bdd25f4e03a27188615d52e6d3","2d9bee437d7844c6be3a22b544bfe661","21f57c6b29ed42aea6c413011a611cd3","cf4f9d1ed6384006908b830c88ec847f","ec0b0710418e4cdabcc91380dc5dd9b6","1985604135c94e4dbd79197500513e3d","87098abf2dd54f4399842585d417bbb2","91cb1dd24ab347959f57bd6e6f8ddee2","ee5d0ed5fdaf448197abd54024529856","75fb30c127da4ec1b6af96eea5ca704c","ba2c86f89a074e7caa439bd913ff5017","52291aaa39d74d0c847932f2be2c29c8","196b2272c07d4c17ab6c4c86aa6a5d8a","a7702ee5cc9f4fd0880ded61fec37af1","53175721c1b8446da30a8bb712e44678","3b5fcfd8e77848cdb97cd8047c0e8192","3ca1dc5282d143c794c17f1f3b31fd64","4a7b0d0321ba4880a5aeda59b7f05acf","54f8676cef634695967ea74f26003347","7d253ab6162044c5ac7a368846f2b6b5","39c6669ffbbe471b8a256d5c7d896936","243920a8bcdb4527b402726bdd7663db","67428da251fc438aadbe98324b7c3e7e","56ccd04348ac4692b7b343ae6775c72b","9ae01a3f52ca4824a99f52d4418e181d"]},"outputId":"6f9ff464-62cd-4274-ce15-d30ac959af43"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9abed31f560248269e4d99f7b8342775"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf4f9d1ed6384006908b830c88ec847f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53175721c1b8446da30a8bb712e44678"}},"metadata":{}}]},{"cell_type":"code","source":["\"\"\"if 't5' in model_checkpoint:\n","    prefix = \"translate Korean to Korean: \"\n","else:\n","    prefix = \"\"\"\"\""],"metadata":{"id":"GVWC91klOAs-","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675133880718,"user_tz":-540,"elapsed":665,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"4e0fde66-f59c-4ecf-9381-e8b9815c6e8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'if \\'t5\\' in model_checkpoint:\\n    prefix = \"translate Korean to Korean: \"\\nelse:\\n    prefix = '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["prefix = \"\""],"metadata":{"id":"_UO2j59Zwu7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["suffix = tokenizer.eos_token"],"metadata":{"id":"wbW5HdRcNgy3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_input_length = 128\n","max_target_length = 128\n","source_lang = \"spoken\"\n","target_lang = \"written\"\n","\n","def preprocess_function(examples):\n","    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n","    targets = [ex[target_lang] + suffix for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"ul0vH316NoOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_function(raw_datasets['train'][:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1ABLDvaONAL","executionInfo":{"status":"ok","timestamp":1675133920837,"user_tz":-540,"elapsed":4,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"e00f9ac9-9285-47d3-ff1d-6cd8020009ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[13425, 222, 2145, 222, 13232, 13, 222, 3956, 222, 624, 279, 222, 965, 1192, 293, 222, 975, 222, 933, 262, 222, 2382, 296, 32, 1], [1205, 222, 2314, 389, 222, 2315, 305, 222, 548, 5879, 222, 1374, 222, 985, 222, 1688, 222, 2438, 296, 15, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[1441, 222, 13425, 222, 3830, 222, 3956, 222, 624, 279, 222, 965, 222, 1192, 279, 222, 770, 222, 334, 491, 222, 933, 262, 222, 13334, 32, 1, 1], [699, 222, 2314, 278, 222, 2315, 222, 305, 222, 8755, 274, 222, 1374, 222, 985, 222, 1688, 278, 222, 738, 15, 1, 1]]}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["f5045cd4ff2144079a7d3a048eb7b145","36b0db75e7b443a1a525de3ca7957799","80f9d15969434004903a9da81b00b30b","208674731b4740c8ac19326d520ce03b","7e810ff9ba5e4b129c1eaaadd4bea8f1","d89d354fbfcb4c629c5b1bb0235a769d","3a9025de651b4e6aa1bad1506ea52b0c","b36065802c7244eaa3e0bdd53fc1a34a","90865089cac34cfdb3c37b4aa83f717b","d2dd054b6ee64428981ef9282945ed3b","54c0d592d9f44fc08f23ea3e1710ae48","c13f46a487f44a08bd8cf653fd3832d6","2037015fedfa459da893a75e047492d4","ea0cf5d34b7e49d788c71e76933bb773","41fa21e15eb34025af797dc7a0f95fcf","aa47704343524bb593501e93ca01bc0d","fef2f07abdf84a6da91c09b64adf4de9","80415c5069cc4db69b7a0863190d9168","052e2f3c3e0b45d8b7947dd8c760fe4c","696c0d3e53a04cb59bc07b5507143af2","17ff2187b18a44369a56fec2d5a79c51","6e16cd5692ed4987aa8f434460a9d226"]},"id":"8LEdn-APWoHu","executionInfo":{"status":"ok","timestamp":1675133924410,"user_tz":-540,"elapsed":722,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"d4e31e9c-4c2e-4439-fcff-98d6c09d2888"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5045cd4ff2144079a7d3a048eb7b145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13f46a487f44a08bd8cf653fd3832d6"}},"metadata":{}}]},{"cell_type":"markdown","source":["# 3️⃣ Fine-tuning the model"],"metadata":{"id":"vVSG0iY1R-zM"}},{"cell_type":"code","source":["\"\"\"metric = load_metric(\"sacrebleu\")\"\"\""],"metadata":{"id":"_kjH8T9_XU26","executionInfo":{"status":"ok","timestamp":1675075355950,"user_tz":-540,"elapsed":53,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a527664f-f091-4330-e32f-56ebe764f43e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'metric = load_metric(\"sacrebleu\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["\"\"\"fake_preds = [\"hello there\", \"general kenobi\"]\n","fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n","metric.compute(predictions=fake_preds, references=fake_labels)\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Qq8LW-NxXrKL","executionInfo":{"status":"ok","timestamp":1675075355956,"user_tz":-540,"elapsed":45,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"47b2c3f0-5ca5-4205-b8e1-edf7e857f72c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'fake_preds = [\"hello there\", \"general kenobi\"]\\nfake_labels = [[\"hello there\"], [\"general kenobi\"]]\\nmetric.compute(predictions=fake_preds, references=fake_labels)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)"],"metadata":{"id":"yMZ86Ja8RqMU","executionInfo":{"status":"ok","timestamp":1675134027656,"user_tz":-540,"elapsed":48051,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["57016c2ccfda4529ada3994ebe248d06","1b0660b217b04dd2b32088e898dc572b","acb3cdd37ad0495d846d5b831dcbef9b","5152e135092f46ef8e8593db76cd9f5a","7585fdc659954a90b03b75a3d1a580a7","4916a758e9dd4b35b5b64ad00a8b079e","a42715db2a414eada46a5148dc1f7d8a","decfcfee765542f2820017eef0a44c48","48806355a58d44aba6253795244628a8","8529e44834144b638a32b2e9cd60bc03","51fbe29b94d04efabdc8e140cfdace05","587332e24c834a7dac2b95b80c99701e","8914834a8cb842adba7b72d4a4362c88","c1415c6b982a4a75976395977a9d9cf9","7be6fbbb37e24bbe81eb2d96c47e5068","03f00e13de4043879d38fb09c6aace97","065a18a952484d828570d60ccc47c549","416cf29f759e4bca9325d0a762009ae2","bf8bd9e6f1dd4f3ca551392247e27bcc","d9c8ee1cf46447e7bd44ba68500a293d","98f19c89a2584af8b31e15dd1c549405","298b896b3e5f4e3297bb1a242ea47215"]},"outputId":"b1ed5b64-c151-4a9a-9bc0-f59aabeb5fbe"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/790 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57016c2ccfda4529ada3994ebe248d06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"587332e24c834a7dac2b95b80c99701e"}},"metadata":{}}]},{"cell_type":"code","source":["epochs = 30\n","batch_size = 16\n","accumulation = 4\n","seed = 42\n","model_name = model_checkpoint.split(\"/\")[-1] + f\"-finetuned-{source_lang}-to-{target_lang}\"\n","\n","args = Seq2SeqTrainingArguments(\n","    model_name,\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_accumulation_steps=accumulation,\n","    weight_decay=0.01,\n","    num_train_epochs=epochs,\n","    logging_strategy='epoch',\n","    save_strategy='epoch',\n","    seed=seed,\n","    fp16=True,\n","    #predict_with_generate=True,\n","    dataloader_num_workers=2,\n","    #report_to = 'wandb',\n","    load_best_model_at_end=True,\n","    push_to_hub=True,\n",")"],"metadata":{"id":"w8D6gQnoSRL-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.init(\n","    project=\"groom-proj3_traslation\",\n","    name = model_name\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"94d6rQZWSeLb","executionInfo":{"status":"ok","timestamp":1675134037151,"user_tz":-540,"elapsed":2737,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"c8b54743-b4e6-4468-ff07-4552efe75dd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myangdk02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/Study/Data Science/AI 자연어 처리 전문가 양성 과정 6기/Project 3/wandb/run-20230131_030033-oibpx5pm</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation/runs/oibpx5pm\" target=\"_blank\">t5-base-korean-paraphrase-finetuned-spoken-to-written</a></strong> to <a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation\" target=\"_blank\">https://wandb.ai/yangdk02/groom-proj3_traslation</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation/runs/oibpx5pm\" target=\"_blank\">https://wandb.ai/yangdk02/groom-proj3_traslation/runs/oibpx5pm</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yangdk02/groom-proj3_traslation/runs/oibpx5pm?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f8ea9dea100>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"W-Uk2GflWDPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    #compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySubH0zpW6N7","executionInfo":{"status":"ok","timestamp":1675134055224,"user_tz":-540,"elapsed":13263,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"5533d242-7b21-4d23-abf1-bf02a648462b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning https://huggingface.co/yangdk/t5-base-korean-paraphrase-finetuned-spoken-to-written into local empty directory.\n","WARNING:huggingface_hub.repository:Cloning https://huggingface.co/yangdk/t5-base-korean-paraphrase-finetuned-spoken-to-written into local empty directory.\n","Using cuda_amp half precision backend\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9BoN66vbW72h","executionInfo":{"status":"ok","timestamp":1675136232117,"user_tz":-540,"elapsed":2174445,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"1f2b570c-0081-4265-9689-a4e251a8ed43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 11012\n","  Num Epochs = 30\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 5160\n","  Number of trainable parameters = 275579136\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2580' max='5160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2580/5160 36:09 < 36:11, 1.19 it/s, Epoch 14/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.054100</td>\n","      <td>0.774273</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.768100</td>\n","      <td>0.700787</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.695900</td>\n","      <td>0.666030</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.645100</td>\n","      <td>0.645646</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.606900</td>\n","      <td>0.630906</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.575600</td>\n","      <td>0.621731</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.547200</td>\n","      <td>0.613836</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.522600</td>\n","      <td>0.611485</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.499100</td>\n","      <td>0.608268</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.479600</td>\n","      <td>0.606045</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.461700</td>\n","      <td>0.606912</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.444300</td>\n","      <td>0.608094</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.428900</td>\n","      <td>0.609505</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.413500</td>\n","      <td>0.612007</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.402100</td>\n","      <td>0.612830</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-172\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-172/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-172/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-172/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-172/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-172/special_tokens_map.json\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-344\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-344/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-344/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-344/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-344/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-344/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-516\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-516/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-516/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-516/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-516/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-516/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-688\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-688/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-688/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-688/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-688/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-688/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-860\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-860/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-860/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-860/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-860/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-860/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1032\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1032/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1032/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1032/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1032/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1032/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1204\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1204/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1204/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1204/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1204/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1204/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1376\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1376/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1376/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1376/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1376/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1376/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1548\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1548/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1548/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1548/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1548/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1548/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1892\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1892/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1892/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1892/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1892/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1892/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2064\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2064/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2064/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2064/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2064/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2064/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2236\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2236/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2236/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2236/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2236/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2236/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2408\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2408/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2408/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2408/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2408/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2408/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2580\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2580/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2580/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2580/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2580/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-2580/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from t5-base-korean-paraphrase-finetuned-spoken-to-written/checkpoint-1720 (score: 0.606044590473175).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2580, training_loss=0.5696510374084, metrics={'train_runtime': 2174.0316, 'train_samples_per_second': 151.957, 'train_steps_per_second': 2.373, 'total_flos': 7111622837329920.0, 'train_loss': 0.5696510374084, 'epoch': 15.0})"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["model.push_to_hub(f\"yangdk/{model_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["3fef29b7a486445591cd645d99b6d0b2","ef59189482cf41df877f32f501567c22","573c5895d03c415784a495ab8ff7251b","eefb318e603a49e884f164244a04d742","2e25355c18194e23af29cde871a1e0d3","b5896750354340599cb6a2c6e0e93a5c","3498440190f540e0ad81ae1353e47544","9ee18ca58d624731b6da997d9dd5e5ae","ab0a4e0b156c4b16905f6b5663a3ee74","194310b9c031461c9813d1c344b7a1aa","41aecfde5921413886162915a2c302b0","35f2de1324344d07999cad2f947001df","a26cf79998e146cead0a23dc05384456","0fd33191246948ab8d07d14b3d15b590","cc8b0117f80141be8082a5d47fb66a2e","4e95a53ce46e4d018f146ec064e0fce5","7b69f5de55e14ffcae080b585940df21","62c97871fb58436cb43b0d39cf3ff659","6649e23c81204a2e813062cdeeb0ef07","17c7c805c04f4360b2783b0aa5cd0097","868444fc85454a59b32c0f4ccee7fffb","afc60c1e71344052a46902a7a74e6e68"]},"id":"joBYM7PatTxq","executionInfo":{"status":"ok","timestamp":1675136292596,"user_tz":-540,"elapsed":60499,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"9cf28e22-c81c-4158-9890-e9b31452de71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-spoken-to-written/pytorch_model.bin\n","Uploading the following files to yangdk/t5-base-korean-paraphrase-finetuned-spoken-to-written: config.json,pytorch_model.bin,generation_config.json\n"]},{"output_type":"display_data","data":{"text/plain":["Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fef29b7a486445591cd645d99b6d0b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35f2de1324344d07999cad2f947001df"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/yangdk/t5-base-korean-paraphrase-finetuned-spoken-to-written/commit/d57aeff36caa7c9ba159be94a7eee9fb1a18ea5b', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='d57aeff36caa7c9ba159be94a7eee9fb1a18ea5b', pr_url=None, pr_revision=None, pr_num=None)"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["# 4️⃣ Inference"],"metadata":{"id":"1ApLl5JRYMWl"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, T5ForConditionalGeneration\n","\n","# You can of course substitute your own username and model here if you've trained and uploaded it!\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = T5ForConditionalGeneration.from_pretrained(f\"yangdk/{model_name}\")\n","model.eval()\n","model.cuda()"],"metadata":{"id":"w4sXwD5EYLGi","executionInfo":{"status":"ok","timestamp":1675136526033,"user_tz":-540,"elapsed":183044,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eb41683683154391b48f12ac18f07c4e","b9d48ba68d8b48d2ad7f978d6a536012","55025c38198e40589b00827024db51a7","446f2b7f7e3c4fa0b7a582a77c5cc712","dd784791cf284e0f9d1687c88e981879","8e9dde4aafaf4d55b42babea1dd5026f","0c78a9ba12f4435ebda329987b157d79","5835194205504b26a8306f9b2ad87e6a","3bce6c60058742ce867cfbaa4a9189f1","d5f1b6ba135c4aa1a9dc21f21f8744af","41931f0cf8c84dc281a0524facdae30d","0eb421ae8dd14f2da7cb946c234de8d3","f560032d7eb04c33b202a89c297330b1","d6f7d98fc3914af386c395d77b2b99d7","39a23a088e734e4c8c0f39bf29d97cbb","8fd2efca674a49b2bcb3fd75bc0e1765","3762b9d09ad24384a7b82e7ee66eb351","3a33129f1c15423184490e27726da213","3a1c07c3ca7a48fcb245426417ca5f80","ef62835a442e4bebbc549be8d1f4a2dd","f442c518bfc6477689b6f5b8d48ef8d2","62f2d8bba90949d1afb48a6eb178998c"]},"outputId":"2373f49c-b86c-4eb0-81e3-e25f148a7f29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file spiece.model from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--lcw99--t5-base-korean-paraphrase/snapshots/ad420deab76699ab627c7d74e61d91ce74f703d5/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--lcw99--t5-base-korean-paraphrase/snapshots/ad420deab76699ab627c7d74e61d91ce74f703d5/special_tokens_map.json\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--lcw99--t5-base-korean-paraphrase/snapshots/ad420deab76699ab627c7d74e61d91ce74f703d5/tokenizer_config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--yangdk--t5-base-korean-paraphrase-finetuned-spoken-to-written/snapshots/d57aeff36caa7c9ba159be94a7eee9fb1a18ea5b/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"lcw99/t5-base-korean-paraphrase\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"max_length\": 512,\n","  \"model_type\": \"t5\",\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb41683683154391b48f12ac18f07c4e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--yangdk--t5-base-korean-paraphrase-finetuned-spoken-to-written/snapshots/d57aeff36caa7c9ba159be94a7eee9fb1a18ea5b/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"max_length\": 512,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at yangdk/t5-base-korean-paraphrase-finetuned-spoken-to-written.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eb421ae8dd14f2da7cb946c234de8d3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--yangdk--t5-base-korean-paraphrase-finetuned-spoken-to-written/snapshots/d57aeff36caa7c9ba159be94a7eee9fb1a18ea5b/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"max_length\": 512,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(50358, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50358, bias=False)\n",")"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["input_text = '정기 시험이 엄청 어려웠어요.'\n","tokenized = tokenizer(input_text, return_attention_mask=False, return_token_type_ids=False, return_tensors='pt')\n","tokenized = {k: v.cuda() for k, v in tokenized.items()}\n","out = model.generate(**tokenized, max_length=128)[0, 1:-1].cpu()\n","print(tokenizer.decode(out, skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-VBBN-dKw7y","executionInfo":{"status":"ok","timestamp":1675136526036,"user_tz":-540,"elapsed":29,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"1def6820-03e8-48e8-fb85-a3cd03bc8e7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"max_length\": 512,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["정기 테스트는 매우 어려웠습니다.\n"]}]}]}