{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM50x+wDOE7QPRwD1Q3xjkR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"974009611ce54a4f9f667e05e45edd91":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_4384c425a1fa451bb2e47daf9e566e3b","IPY_MODEL_ad4e9e2f71e945e3bb1e812281281802","IPY_MODEL_e8c4d51ba5ae48579297e5fc8c1ba1ed","IPY_MODEL_8cd9a564b4dd4946984a9ba7daa20285","IPY_MODEL_c4d2ed3a7d93498cbe6a96f2affb1b44"],"layout":"IPY_MODEL_2438795ef654423d8955d783ea8cfdb0"}},"4384c425a1fa451bb2e47daf9e566e3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_748821054d97480283cd98e16a6cf4a1","placeholder":"​","style":"IPY_MODEL_13add6d818bb455888935bbda9b60b34","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"ad4e9e2f71e945e3bb1e812281281802":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5649543478154e5993a08dec004c6eb5","placeholder":"​","style":"IPY_MODEL_4e001137aef3463491bab01172680949","value":""}},"e8c4d51ba5ae48579297e5fc8c1ba1ed":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_f190946d70d0490b80d54a566c91370e","style":"IPY_MODEL_613dc238924840d3a8917b81d71238e0","value":true}},"8cd9a564b4dd4946984a9ba7daa20285":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_a2d95e2911b64b969191a5725474f11b","style":"IPY_MODEL_d53f36b6113348b788a50fb24614dd62","tooltip":""}},"c4d2ed3a7d93498cbe6a96f2affb1b44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6693de9c6e34b3baf8c2b090a96ac72","placeholder":"​","style":"IPY_MODEL_92670f7c6d85487881195453240925bf","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"2438795ef654423d8955d783ea8cfdb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"748821054d97480283cd98e16a6cf4a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13add6d818bb455888935bbda9b60b34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5649543478154e5993a08dec004c6eb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e001137aef3463491bab01172680949":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f190946d70d0490b80d54a566c91370e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"613dc238924840d3a8917b81d71238e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2d95e2911b64b969191a5725474f11b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d53f36b6113348b788a50fb24614dd62":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"f6693de9c6e34b3baf8c2b090a96ac72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92670f7c6d85487881195453240925bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34e5690eb4784907a71a1ff0f8fe7f99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47588bdea0cd4c8b87c89de6839ada08","IPY_MODEL_d1af421cd24f4b1e8addeeea7ceee80e","IPY_MODEL_6ce62fec7e02439c8d96dcc2c5ee9a1d"],"layout":"IPY_MODEL_14e05a97242b40d3a06f5ad2f478c976"}},"47588bdea0cd4c8b87c89de6839ada08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a49269061ee94bbfa234dbd3268d076f","placeholder":"​","style":"IPY_MODEL_47cd437c0998405e8655c0ddcdb63203","value":"Downloading (…)okenizer_config.json: 100%"}},"d1af421cd24f4b1e8addeeea7ceee80e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_044b77ccaf3a4b5599c5b005aa476ddb","max":2403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_364724582fab44b29bcd9541f551ee99","value":2403}},"6ce62fec7e02439c8d96dcc2c5ee9a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5394c259cfe3456884e0e7e14f597f93","placeholder":"​","style":"IPY_MODEL_8f7780ef2bd246ed9f1f28ab30253902","value":" 2.40k/2.40k [00:00&lt;00:00, 116kB/s]"}},"14e05a97242b40d3a06f5ad2f478c976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a49269061ee94bbfa234dbd3268d076f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47cd437c0998405e8655c0ddcdb63203":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"044b77ccaf3a4b5599c5b005aa476ddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"364724582fab44b29bcd9541f551ee99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5394c259cfe3456884e0e7e14f597f93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f7780ef2bd246ed9f1f28ab30253902":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"362113ca4f2843449f3960b7467a24e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29e08b588d0047d5b49f8879af632c1c","IPY_MODEL_5297b171d97541d29c4fd5f3e7281246","IPY_MODEL_3e476ffafad34ebe862952cc493c7eb5"],"layout":"IPY_MODEL_9606673b445b489e81efaef912535b06"}},"29e08b588d0047d5b49f8879af632c1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e77b074a50e4ac9b1b3acc238a9e8ac","placeholder":"​","style":"IPY_MODEL_fc63fdb4d7ed45fdb2afe6b19c9afd24","value":"Downloading (…)/main/tokenizer.json: 100%"}},"5297b171d97541d29c4fd5f3e7281246":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51d9a90288d0486b8bab4449d9d902bb","max":2919674,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2f6787fc4f247b9b7e55c7b4831f455","value":2919674}},"3e476ffafad34ebe862952cc493c7eb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_194ca97f1a904df6bf7ea32ae7605664","placeholder":"​","style":"IPY_MODEL_27f1a96cf622480293e68ade3b5ad8c9","value":" 2.92M/2.92M [00:00&lt;00:00, 4.86MB/s]"}},"9606673b445b489e81efaef912535b06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e77b074a50e4ac9b1b3acc238a9e8ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc63fdb4d7ed45fdb2afe6b19c9afd24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51d9a90288d0486b8bab4449d9d902bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f6787fc4f247b9b7e55c7b4831f455":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"194ca97f1a904df6bf7ea32ae7605664":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27f1a96cf622480293e68ade3b5ad8c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23245a2929304c23ba1a22c305e1d631":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78fe25cc68534915abbeba1f9a43d038","IPY_MODEL_2687c5b47a22400d831642f40e177bc9","IPY_MODEL_9d32e613702b4f8b8f3db1bbf18ecb32"],"layout":"IPY_MODEL_6556c84b90e341ab99056e89e271968d"}},"78fe25cc68534915abbeba1f9a43d038":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af30adfac99f4d2a8f10fc5506141248","placeholder":"​","style":"IPY_MODEL_56e105f42d544215854fa33f7ed85190","value":"Downloading (…)cial_tokens_map.json: 100%"}},"2687c5b47a22400d831642f40e177bc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30c309ae9d7446d3ad0a1c3838e688fb","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8774b99f91f84d17a70035120124349d","value":2201}},"9d32e613702b4f8b8f3db1bbf18ecb32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4fe58f07a0d4e818a0c7fc2081239d2","placeholder":"​","style":"IPY_MODEL_b222eb8029334415977b9439ac140c26","value":" 2.20k/2.20k [00:00&lt;00:00, 158kB/s]"}},"6556c84b90e341ab99056e89e271968d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af30adfac99f4d2a8f10fc5506141248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56e105f42d544215854fa33f7ed85190":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30c309ae9d7446d3ad0a1c3838e688fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8774b99f91f84d17a70035120124349d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4fe58f07a0d4e818a0c7fc2081239d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b222eb8029334415977b9439ac140c26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81dd4ad520f7464badc407e80e2af51d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2105f8897f9f4160a3a631bd7d6a3c07","IPY_MODEL_164423539e93414aa31c62dac1d010a6","IPY_MODEL_6605cfbdaeea401ca080398bd0e53349"],"layout":"IPY_MODEL_f2b0961466874a46b8e823a7cf4a277c"}},"2105f8897f9f4160a3a631bd7d6a3c07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72edeff7919d493f92e8531536d3921f","placeholder":"​","style":"IPY_MODEL_9b9d3bc78b24480d8986a58f6b4ca657","value":"100%"}},"164423539e93414aa31c62dac1d010a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58315ebb82a44979dd7f2a78184267d","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_060db6669f0145968107e267caca6a7a","value":12}},"6605cfbdaeea401ca080398bd0e53349":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df074883c68340b1b9d572895553e668","placeholder":"​","style":"IPY_MODEL_c4fbaffee1754254968d0236fc1546fe","value":" 12/12 [00:00&lt;00:00, 17.52ba/s]"}},"f2b0961466874a46b8e823a7cf4a277c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72edeff7919d493f92e8531536d3921f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b9d3bc78b24480d8986a58f6b4ca657":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e58315ebb82a44979dd7f2a78184267d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"060db6669f0145968107e267caca6a7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df074883c68340b1b9d572895553e668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4fbaffee1754254968d0236fc1546fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee98b0a991264bb099ef553010265623":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0103067d19c74242bc43bec250aef54d","IPY_MODEL_8058035254f64e33adf6e322cb46601a","IPY_MODEL_40bd68997d474b588dfc41ecd297b48a"],"layout":"IPY_MODEL_1ca02a6e818d41f58914831b79903ac1"}},"0103067d19c74242bc43bec250aef54d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d301eb5ce4724e8b8dd1d9969b18bca4","placeholder":"​","style":"IPY_MODEL_18defa5bb05d45d7a689b940e45018fd","value":"100%"}},"8058035254f64e33adf6e322cb46601a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c19b241b622f4fd19ad3e57102122352","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8b75cc7bbe54195ba086d0a3d330f91","value":3}},"40bd68997d474b588dfc41ecd297b48a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8af1d0d082144d4182140dce5b2e8da2","placeholder":"​","style":"IPY_MODEL_02b8498d95ba4622ae54ce2085445b41","value":" 3/3 [00:00&lt;00:00, 15.42ba/s]"}},"1ca02a6e818d41f58914831b79903ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d301eb5ce4724e8b8dd1d9969b18bca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18defa5bb05d45d7a689b940e45018fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c19b241b622f4fd19ad3e57102122352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b75cc7bbe54195ba086d0a3d330f91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8af1d0d082144d4182140dce5b2e8da2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b8498d95ba4622ae54ce2085445b41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ec2650024654117baf4fd8e0d05d62a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d51840cfc4c420ca9ea7f6d4469f6f1","IPY_MODEL_f2a69c35a13249dfae3557a387125cb9","IPY_MODEL_9c19e5cb5f02427089cad6642c07e8e5"],"layout":"IPY_MODEL_063c24d38115499383e1dfe927a383b3"}},"6d51840cfc4c420ca9ea7f6d4469f6f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a0804951c4420b83d27802adb3122e","placeholder":"​","style":"IPY_MODEL_32cc85aa1ec84ffba1f88ee4b3854655","value":"Downloading (…)lve/main/config.json: 100%"}},"f2a69c35a13249dfae3557a387125cb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81b67828eba548ddafb1b2702fee2f34","max":790,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d51981542d5489a8209a187a7ea76b2","value":790}},"9c19e5cb5f02427089cad6642c07e8e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52b846ec1b51454099de544b5b05ec87","placeholder":"​","style":"IPY_MODEL_0aa812f9ed244acdb3458db9a8ef13b9","value":" 790/790 [00:00&lt;00:00, 48.2kB/s]"}},"063c24d38115499383e1dfe927a383b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a0804951c4420b83d27802adb3122e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32cc85aa1ec84ffba1f88ee4b3854655":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81b67828eba548ddafb1b2702fee2f34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d51981542d5489a8209a187a7ea76b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52b846ec1b51454099de544b5b05ec87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aa812f9ed244acdb3458db9a8ef13b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7244a4690e5d4d80a6ad68d4b5dd05fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ce9b3b3dcc148b2961eae61c9849ac0","IPY_MODEL_7c7f9d04a2ff4306b713b7e2779cf522","IPY_MODEL_c3d5cd94805a469cbb19b51601cf87ef"],"layout":"IPY_MODEL_6180a886eb5c458ca0a795a27fdf3597"}},"5ce9b3b3dcc148b2961eae61c9849ac0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fa7b6fe492849e49a339e5e96f3a208","placeholder":"​","style":"IPY_MODEL_4c3bb4e0787e421bb4f78f86ed8c204b","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"7c7f9d04a2ff4306b713b7e2779cf522":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_adfde02a20754d2cb22bbe94898b4388","max":1102407757,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36abde359bd34fceb1c0e9a1e03006ad","value":1102407757}},"c3d5cd94805a469cbb19b51601cf87ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67e29d359e3643d19e3f2b90bfa2db67","placeholder":"​","style":"IPY_MODEL_5f6869b23b8e4f00aabbb3e2eb8f080c","value":" 1.10G/1.10G [00:32&lt;00:00, 33.3MB/s]"}},"6180a886eb5c458ca0a795a27fdf3597":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fa7b6fe492849e49a339e5e96f3a208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c3bb4e0787e421bb4f78f86ed8c204b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adfde02a20754d2cb22bbe94898b4388":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36abde359bd34fceb1c0e9a1e03006ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67e29d359e3643d19e3f2b90bfa2db67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f6869b23b8e4f00aabbb3e2eb8f080c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4f1ef800548453a932ee7faecf966f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6b35a70c64d4ac3ae15073bd4959d18","IPY_MODEL_ce4373a144564e07973ab93511fcafb0","IPY_MODEL_cef8f5801a194bb0803d17e0117ec8e4"],"layout":"IPY_MODEL_000fce0b61d74846b1b519f5632ea146"}},"f6b35a70c64d4ac3ae15073bd4959d18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2800c259fb5f466ca0090c269c5e71db","placeholder":"​","style":"IPY_MODEL_e8ca64592bbf4489af9753166597c195","value":"Upload 1 LFS files: 100%"}},"ce4373a144564e07973ab93511fcafb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be5e649d9c704290a35db752a22c7f64","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0f760b126314ec7ac352e5a6bf236d1","value":1}},"cef8f5801a194bb0803d17e0117ec8e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9cbd23410744d8b9796068e11420c8","placeholder":"​","style":"IPY_MODEL_5956ae3ced414b4983c4f533e593bf13","value":" 1/1 [00:35&lt;00:00, 35.63s/it]"}},"000fce0b61d74846b1b519f5632ea146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2800c259fb5f466ca0090c269c5e71db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8ca64592bbf4489af9753166597c195":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be5e649d9c704290a35db752a22c7f64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f760b126314ec7ac352e5a6bf236d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b9cbd23410744d8b9796068e11420c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5956ae3ced414b4983c4f533e593bf13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea425a07885b4ed1ba84c326c74ff59d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75f46ac5bf644c22bbc0338f3f59afd9","IPY_MODEL_55fb489a7c6b4470984a4e6405351aba","IPY_MODEL_06fc5ed2b2fc4d89bd3fc1880bcc1878"],"layout":"IPY_MODEL_d26f1900cad6478d9cf98e44881a3d3a"}},"75f46ac5bf644c22bbc0338f3f59afd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a17241b48894c3fbd93a6ea47ebb9d0","placeholder":"​","style":"IPY_MODEL_838f0fb02ad741f1807180d7a871d035","value":"pytorch_model.bin: 100%"}},"55fb489a7c6b4470984a4e6405351aba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25186637ad16497ab7aa72e04633b1a7","max":1102414005,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f98b820c454742fe8e33af1fdec9ebf1","value":1102414005}},"06fc5ed2b2fc4d89bd3fc1880bcc1878":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d33a1e79d3774473bae7f0daa3b0a0c9","placeholder":"​","style":"IPY_MODEL_df84a443233a4314b94ad237974fa09e","value":" 1.10G/1.10G [00:35&lt;00:00, 35.4MB/s]"}},"d26f1900cad6478d9cf98e44881a3d3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a17241b48894c3fbd93a6ea47ebb9d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"838f0fb02ad741f1807180d7a871d035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25186637ad16497ab7aa72e04633b1a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98b820c454742fe8e33af1fdec9ebf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d33a1e79d3774473bae7f0daa3b0a0c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df84a443233a4314b94ad237974fa09e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee5fba13ec8a4984a2e01b23f2f4d962":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3f1db7860784c38ab075d9fdf99e4ed","IPY_MODEL_18e9e3322eb34bdb8f20a8842bdc38e1","IPY_MODEL_e965316bb9a64dd18913ae9c66c414f3"],"layout":"IPY_MODEL_71e6401cf3534f6eb6809fe218950f7f"}},"e3f1db7860784c38ab075d9fdf99e4ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0548afe2daf9456b81503cc7a608dde5","placeholder":"​","style":"IPY_MODEL_c45b257e90e04fb5bae740ec98847a0a","value":"Downloading (…)lve/main/config.json: 100%"}},"18e9e3322eb34bdb8f20a8842bdc38e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_785381b922514d419c99150430d3fda5","max":796,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a1cef1831d440d0ba5e55c8f93f6e1e","value":796}},"e965316bb9a64dd18913ae9c66c414f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82583b5a59c048ea88729436d8a0d5c0","placeholder":"​","style":"IPY_MODEL_72d6fc222bc94661b0fe1d3b96680943","value":" 796/796 [00:00&lt;00:00, 54.6kB/s]"}},"71e6401cf3534f6eb6809fe218950f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0548afe2daf9456b81503cc7a608dde5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45b257e90e04fb5bae740ec98847a0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"785381b922514d419c99150430d3fda5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a1cef1831d440d0ba5e55c8f93f6e1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82583b5a59c048ea88729436d8a0d5c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72d6fc222bc94661b0fe1d3b96680943":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b1c88953c184bc18a46b427f4bde226":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36e6a057b028425d8ed425ca02f60993","IPY_MODEL_ffec61b81be64ad3bf9ec5a0cca5e986","IPY_MODEL_5e86bc3475a64b5a8d6204d1237d8df0"],"layout":"IPY_MODEL_af75b0270847429a931d4aa866e7eb6a"}},"36e6a057b028425d8ed425ca02f60993":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48c3aed52197410eb75d549c02d9da2a","placeholder":"​","style":"IPY_MODEL_972285bee07f4228ab3dfbac9aefa363","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"ffec61b81be64ad3bf9ec5a0cca5e986":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e42fa79240a44e4c877dd23bd381dfb7","max":1102414005,"min":0,"orientation":"horizontal","style":"IPY_MODEL_987a1061e3aa405aa7b87104656d9bc0","value":1102414005}},"5e86bc3475a64b5a8d6204d1237d8df0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4967d1d4699c4fa5acff660dd5409c0c","placeholder":"​","style":"IPY_MODEL_7358ec6e710a46e19e3cab21d1c4af41","value":" 1.10G/1.10G [00:26&lt;00:00, 42.0MB/s]"}},"af75b0270847429a931d4aa866e7eb6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c3aed52197410eb75d549c02d9da2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"972285bee07f4228ab3dfbac9aefa363":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e42fa79240a44e4c877dd23bd381dfb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"987a1061e3aa405aa7b87104656d9bc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4967d1d4699c4fa5acff660dd5409c0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7358ec6e710a46e19e3cab21d1c4af41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d40dba04ef244b49a73ba3d0a77c8ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc06008184d54e9fafa80ad85af896df","IPY_MODEL_af4deeac797f44f4b228ddf8234cb9b0","IPY_MODEL_ccdac82e812a44218d78d522246214aa"],"layout":"IPY_MODEL_2f65dab45e584b9892e031cee0675960"}},"fc06008184d54e9fafa80ad85af896df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a60296d63395429786445d458adbff89","placeholder":"​","style":"IPY_MODEL_e21bb0969e1a4b02afde64b78d469ef5","value":"Downloading (…)neration_config.json: 100%"}},"af4deeac797f44f4b228ddf8234cb9b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97fb0f6a7ac248c2bb950822077dfcb9","max":163,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c294f19d302f41d2aa2708bfc90bbc86","value":163}},"ccdac82e812a44218d78d522246214aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9c93385fde34f51ac9078254b244b46","placeholder":"​","style":"IPY_MODEL_dd906cf5b0b0478483158f17d87c4f2a","value":" 163/163 [00:00&lt;00:00, 8.33kB/s]"}},"2f65dab45e584b9892e031cee0675960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a60296d63395429786445d458adbff89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e21bb0969e1a4b02afde64b78d469ef5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97fb0f6a7ac248c2bb950822077dfcb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c294f19d302f41d2aa2708bfc90bbc86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9c93385fde34f51ac9078254b244b46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd906cf5b0b0478483158f17d87c4f2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 📖 References\n","\n","- https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb\n","- https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb\n","- https://huggingface.co/gogamza/kobart-base-v2"],"metadata":{"id":"bEJn20VNO-mH"}},{"cell_type":"markdown","source":["# 0️⃣ Prerequisite"],"metadata":{"id":"aLK88AVoI6sV"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"JLTgv42uPHVn"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4T0Dfks1I1eo","executionInfo":{"status":"ok","timestamp":1675136726590,"user_tz":-540,"elapsed":25194,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"32f01ffc-51d1-4187-bda9-3ed3403cad1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruWg5bfNJBCm","executionInfo":{"status":"ok","timestamp":1675136727194,"user_tz":-540,"elapsed":611,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"69bea318-8c7e-4759-d8ae-87909f83495f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Jan 31 03:45:25 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/Study/Data Science/AI 자연어 처리 전문가 양성 과정 6기/Project 3')"],"metadata":{"id":"QQDvMpFtJHMg","executionInfo":{"status":"ok","timestamp":1675136727194,"user_tz":-540,"elapsed":7,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install -q datasets torchinfo transformers sacrebleu sentencepiece wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aqp5S07JXNG","executionInfo":{"status":"ok","timestamp":1675136746281,"user_tz":-540,"elapsed":19093,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"5d596869-888e-4990-dc0f-7b58bb6a463a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict, load_dataset, load_metric\n","from easydict import EasyDict as edict\n","from sklearn.model_selection import train_test_split\n","from torchinfo import summary\n","from transformers import (\n","    AutoTokenizer,\n","    T5ForConditionalGeneration,\n","    DataCollatorForSeq2Seq,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    EarlyStoppingCallback,\n",")\n","\n","import numpy as np\n","import pandas as pd\n","import random\n","import sentencepiece\n","import torch"],"metadata":{"id":"KaqaaE_6JbY0","executionInfo":{"status":"ok","timestamp":1675136752347,"user_tz":-540,"elapsed":6072,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Log in to your W&B account\n","import wandb\n","\n","wandb.login(key='eeef6909a6674c953c756358e614461bdced83c4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bh9vqJxqJY-7","executionInfo":{"status":"ok","timestamp":1675136757884,"user_tz":-540,"elapsed":5542,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"28ce5d09-412f-46af-fd7b-b105c1d41eb1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303,"referenced_widgets":["974009611ce54a4f9f667e05e45edd91","4384c425a1fa451bb2e47daf9e566e3b","ad4e9e2f71e945e3bb1e812281281802","e8c4d51ba5ae48579297e5fc8c1ba1ed","8cd9a564b4dd4946984a9ba7daa20285","c4d2ed3a7d93498cbe6a96f2affb1b44","2438795ef654423d8955d783ea8cfdb0","748821054d97480283cd98e16a6cf4a1","13add6d818bb455888935bbda9b60b34","5649543478154e5993a08dec004c6eb5","4e001137aef3463491bab01172680949","f190946d70d0490b80d54a566c91370e","613dc238924840d3a8917b81d71238e0","a2d95e2911b64b969191a5725474f11b","d53f36b6113348b788a50fb24614dd62","f6693de9c6e34b3baf8c2b090a96ac72","92670f7c6d85487881195453240925bf"]},"id":"AHBWGNPBsP7m","executionInfo":{"status":"ok","timestamp":1675136757886,"user_tz":-540,"elapsed":14,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"7a9d1421-9f38-4b18-ef18-d5fe7b51d8b1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid.\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["def seed_everthing(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everthing(42)"],"metadata":{"id":"BSLpJoDNMVh4","executionInfo":{"status":"ok","timestamp":1675136779847,"user_tz":-540,"elapsed":453,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# 1️⃣ Loading the dataset"],"metadata":{"id":"TDq5TWYyJ4JW"}},{"cell_type":"code","source":["\"\"\"df_a = pd.read_csv('output/df_spoken-written_a.csv')\n","df_a.columns = ['id', 'spoken', 'written']\n","\n","df_b = pd.read_csv('output/df_spoken-written_b.csv')\n","df_b.columns = ['id', 'spoken', 'written']\n","\n","df = pd.concat([df_a, df_b])\"\"\""],"metadata":{"id":"SxxnATe0LmYX","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675136781045,"user_tz":-540,"elapsed":11,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"56cde9d5-134e-45a9-bb76-bee3dacacd7a"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"df_a = pd.read_csv('output/df_spoken-written_a.csv')\\ndf_a.columns = ['id', 'spoken', 'written']\\n\\ndf_b = pd.read_csv('output/df_spoken-written_b.csv')\\ndf_b.columns = ['id', 'spoken', 'written']\\n\\ndf = pd.concat([df_a, df_b])\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\"\"\"df_train, df_validation = train_test_split(df, test_size=0.2, random_state=42)\n","df_train.to_csv('input/df_spoken-written_train.csv', index=False)\n","df_validation.to_csv('input/df_spoken-written_validation.csv', index=False)\"\"\""],"metadata":{"id":"qw_Gnrx_LpRL","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675136781046,"user_tz":-540,"elapsed":10,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"bb6dfb9a-e084-4aa0-d1f9-4ec2f401e912"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"df_train, df_validation = train_test_split(df, test_size=0.2, random_state=42)\\ndf_train.to_csv('input/df_spoken-written_train.csv', index=False)\\ndf_validation.to_csv('input/df_spoken-written_validation.csv', index=False)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df_train = pd.read_csv('input/df_spoken-written_train.csv')\n","df_validation = pd.read_csv('input/df_spoken-written_validation.csv')"],"metadata":{"id":"NmajqzsLQtP6","executionInfo":{"status":"ok","timestamp":1675136782646,"user_tz":-540,"elapsed":667,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["ds_train = Dataset.from_dict({'translation': df_train[['spoken', 'written']].to_dict('records')})\n","ds_validation = Dataset.from_dict({'translation': df_validation[['spoken', 'written']].to_dict('records')})"],"metadata":{"id":"N78HqE2RQPBF","executionInfo":{"status":"ok","timestamp":1675136783124,"user_tz":-540,"elapsed":490,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["raw_datasets = DatasetDict({\n","    \"train\": ds_train,\n","    \"validation\": ds_validation})"],"metadata":{"id":"kR1YfVsvUdwg","executionInfo":{"status":"ok","timestamp":1675136783628,"user_tz":-540,"elapsed":4,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(\"Number of Train Samples:\", len(raw_datasets['train']))\n","print(\"Number of Validation Samples:\", len(raw_datasets['validation']))\n","print(raw_datasets['train'][0])\n","print(raw_datasets['validation'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Up6fCf5sLgMc","executionInfo":{"status":"ok","timestamp":1675136783629,"user_tz":-540,"elapsed":5,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"de617781-9f0e-4576-dd30-1c12c070587d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Train Samples: 11012\n","Number of Validation Samples: 2754\n","{'translation': {'spoken': '차가 없어서 그러는데, 택시 외에 쇼핑센터로 가는 방법이 있나요?', 'written': '나는 차가 없지만 택시 외에 쇼핑 센터에 갈 수있는 방법이 있습니까?'}}\n","{'translation': {'spoken': '이 불고기 맛이 너무 환상적인데 어떻게 만드셨나요?', 'written': '이 불고기 맛은 매우 환상적입니다.어떻게 만들었습니까?'}}\n"]}]},{"cell_type":"code","source":["del df_train, df_validation\n","del ds_train, ds_validation\n","\n","import gc\n","gc.collect()"],"metadata":{"id":"zeFlPLaGVurF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675136785176,"user_tz":-540,"elapsed":4,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"cf1d02de-eb5f-4cbd-d5b5-03c9e78d35de"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1292"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# 2️⃣ Preprocessing the data"],"metadata":{"id":"nkazXujmMV-j"}},{"cell_type":"code","source":["model_checkpoint = 'lcw99/t5-base-korean-paraphrase'"],"metadata":{"id":"cMrUO0foMtZc","executionInfo":{"status":"ok","timestamp":1675136786807,"user_tz":-540,"elapsed":3,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"id":"KiPV6LwmL3Fx","executionInfo":{"status":"ok","timestamp":1675136791360,"user_tz":-540,"elapsed":3616,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["34e5690eb4784907a71a1ff0f8fe7f99","47588bdea0cd4c8b87c89de6839ada08","d1af421cd24f4b1e8addeeea7ceee80e","6ce62fec7e02439c8d96dcc2c5ee9a1d","14e05a97242b40d3a06f5ad2f478c976","a49269061ee94bbfa234dbd3268d076f","47cd437c0998405e8655c0ddcdb63203","044b77ccaf3a4b5599c5b005aa476ddb","364724582fab44b29bcd9541f551ee99","5394c259cfe3456884e0e7e14f597f93","8f7780ef2bd246ed9f1f28ab30253902","362113ca4f2843449f3960b7467a24e9","29e08b588d0047d5b49f8879af632c1c","5297b171d97541d29c4fd5f3e7281246","3e476ffafad34ebe862952cc493c7eb5","9606673b445b489e81efaef912535b06","4e77b074a50e4ac9b1b3acc238a9e8ac","fc63fdb4d7ed45fdb2afe6b19c9afd24","51d9a90288d0486b8bab4449d9d902bb","c2f6787fc4f247b9b7e55c7b4831f455","194ca97f1a904df6bf7ea32ae7605664","27f1a96cf622480293e68ade3b5ad8c9","23245a2929304c23ba1a22c305e1d631","78fe25cc68534915abbeba1f9a43d038","2687c5b47a22400d831642f40e177bc9","9d32e613702b4f8b8f3db1bbf18ecb32","6556c84b90e341ab99056e89e271968d","af30adfac99f4d2a8f10fc5506141248","56e105f42d544215854fa33f7ed85190","30c309ae9d7446d3ad0a1c3838e688fb","8774b99f91f84d17a70035120124349d","a4fe58f07a0d4e818a0c7fc2081239d2","b222eb8029334415977b9439ac140c26"]},"outputId":"418f840f-d47c-43b1-c20a-5d1849feaecb"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e5690eb4784907a71a1ff0f8fe7f99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"362113ca4f2843449f3960b7467a24e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23245a2929304c23ba1a22c305e1d631"}},"metadata":{}}]},{"cell_type":"code","source":["\"\"\"if 't5' in model_checkpoint:\n","    prefix = \"translate Korean to Korean: \"\n","else:\n","    prefix = \"\"\"\"\""],"metadata":{"id":"GVWC91klOAs-","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675136791361,"user_tz":-540,"elapsed":16,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"2dc7772c-6469-4e41-935f-8d76ed985ec5"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'if \\'t5\\' in model_checkpoint:\\n    prefix = \"translate Korean to Korean: \"\\nelse:\\n    prefix = '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["prefix = \"\""],"metadata":{"id":"_UO2j59Zwu7p","executionInfo":{"status":"ok","timestamp":1675136791362,"user_tz":-540,"elapsed":14,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["suffix = tokenizer.eos_token"],"metadata":{"id":"wbW5HdRcNgy3","executionInfo":{"status":"ok","timestamp":1675136791362,"user_tz":-540,"elapsed":12,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["max_input_length = 128\n","max_target_length = 128\n","source_lang = \"written\"\n","target_lang = \"spoken\"\n","\n","def preprocess_function(examples):\n","    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n","    targets = [ex[target_lang] + suffix for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"ul0vH316NoOD","executionInfo":{"status":"ok","timestamp":1675136800419,"user_tz":-540,"elapsed":552,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["preprocess_function(raw_datasets['train'][:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1ABLDvaONAL","executionInfo":{"status":"ok","timestamp":1675136803445,"user_tz":-540,"elapsed":5,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"70ee8454-51e0-4de3-bbf7-9c556d02297b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[1441, 222, 13425, 222, 3830, 222, 3956, 222, 624, 279, 222, 965, 222, 1192, 279, 222, 770, 222, 334, 491, 222, 933, 262, 222, 13334, 32, 1], [699, 222, 2314, 278, 222, 2315, 222, 305, 222, 8755, 274, 222, 1374, 222, 985, 222, 1688, 278, 222, 738, 15, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[13425, 222, 2145, 222, 13232, 13, 222, 3956, 222, 624, 279, 222, 965, 1192, 293, 222, 975, 222, 933, 262, 222, 2382, 296, 32, 1, 1], [1205, 222, 2314, 389, 222, 2315, 305, 222, 548, 5879, 222, 1374, 222, 985, 222, 1688, 222, 2438, 296, 15, 1, 1]]}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["81dd4ad520f7464badc407e80e2af51d","2105f8897f9f4160a3a631bd7d6a3c07","164423539e93414aa31c62dac1d010a6","6605cfbdaeea401ca080398bd0e53349","f2b0961466874a46b8e823a7cf4a277c","72edeff7919d493f92e8531536d3921f","9b9d3bc78b24480d8986a58f6b4ca657","e58315ebb82a44979dd7f2a78184267d","060db6669f0145968107e267caca6a7a","df074883c68340b1b9d572895553e668","c4fbaffee1754254968d0236fc1546fe","ee98b0a991264bb099ef553010265623","0103067d19c74242bc43bec250aef54d","8058035254f64e33adf6e322cb46601a","40bd68997d474b588dfc41ecd297b48a","1ca02a6e818d41f58914831b79903ac1","d301eb5ce4724e8b8dd1d9969b18bca4","18defa5bb05d45d7a689b940e45018fd","c19b241b622f4fd19ad3e57102122352","d8b75cc7bbe54195ba086d0a3d330f91","8af1d0d082144d4182140dce5b2e8da2","02b8498d95ba4622ae54ce2085445b41"]},"id":"8LEdn-APWoHu","executionInfo":{"status":"ok","timestamp":1675136805756,"user_tz":-540,"elapsed":866,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"996e3284-11f3-4f33-8654-35298255259b"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81dd4ad520f7464badc407e80e2af51d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee98b0a991264bb099ef553010265623"}},"metadata":{}}]},{"cell_type":"markdown","source":["# 3️⃣ Fine-tuning the model"],"metadata":{"id":"vVSG0iY1R-zM"}},{"cell_type":"code","source":["\"\"\"metric = load_metric(\"sacrebleu\")\"\"\""],"metadata":{"id":"_kjH8T9_XU26","executionInfo":{"status":"ok","timestamp":1675136807080,"user_tz":-540,"elapsed":7,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5861e9be-4f2e-43ed-ebb9-a74e9156fca9"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'metric = load_metric(\"sacrebleu\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["\"\"\"fake_preds = [\"hello there\", \"general kenobi\"]\n","fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n","metric.compute(predictions=fake_preds, references=fake_labels)\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Qq8LW-NxXrKL","executionInfo":{"status":"ok","timestamp":1675136807580,"user_tz":-540,"elapsed":10,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"738ea13f-0317-4239-a9aa-4ccf99d42c11"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'fake_preds = [\"hello there\", \"general kenobi\"]\\nfake_labels = [[\"hello there\"], [\"general kenobi\"]]\\nmetric.compute(predictions=fake_preds, references=fake_labels)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)"],"metadata":{"id":"yMZ86Ja8RqMU","executionInfo":{"status":"ok","timestamp":1675136846880,"user_tz":-540,"elapsed":38035,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["7ec2650024654117baf4fd8e0d05d62a","6d51840cfc4c420ca9ea7f6d4469f6f1","f2a69c35a13249dfae3557a387125cb9","9c19e5cb5f02427089cad6642c07e8e5","063c24d38115499383e1dfe927a383b3","a1a0804951c4420b83d27802adb3122e","32cc85aa1ec84ffba1f88ee4b3854655","81b67828eba548ddafb1b2702fee2f34","5d51981542d5489a8209a187a7ea76b2","52b846ec1b51454099de544b5b05ec87","0aa812f9ed244acdb3458db9a8ef13b9","7244a4690e5d4d80a6ad68d4b5dd05fa","5ce9b3b3dcc148b2961eae61c9849ac0","7c7f9d04a2ff4306b713b7e2779cf522","c3d5cd94805a469cbb19b51601cf87ef","6180a886eb5c458ca0a795a27fdf3597","7fa7b6fe492849e49a339e5e96f3a208","4c3bb4e0787e421bb4f78f86ed8c204b","adfde02a20754d2cb22bbe94898b4388","36abde359bd34fceb1c0e9a1e03006ad","67e29d359e3643d19e3f2b90bfa2db67","5f6869b23b8e4f00aabbb3e2eb8f080c"]},"outputId":"45f94fcd-07f8-467b-c675-1d162d4035df"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/790 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec2650024654117baf4fd8e0d05d62a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7244a4690e5d4d80a6ad68d4b5dd05fa"}},"metadata":{}}]},{"cell_type":"code","source":["epochs = 30\n","batch_size = 16\n","accumulation = 4\n","seed = 42\n","model_name = model_checkpoint.split(\"/\")[-1] + f\"-finetuned-{source_lang}-to-{target_lang}\"\n","\n","args = Seq2SeqTrainingArguments(\n","    model_name,\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_accumulation_steps=accumulation,\n","    weight_decay=0.01,\n","    num_train_epochs=epochs,\n","    logging_strategy='epoch',\n","    save_strategy='epoch',\n","    seed=seed,\n","    fp16=True,\n","    #predict_with_generate=True,\n","    dataloader_num_workers=2,\n","    #report_to = 'wandb',\n","    load_best_model_at_end=True,\n","    push_to_hub=True,\n",")"],"metadata":{"id":"w8D6gQnoSRL-","executionInfo":{"status":"ok","timestamp":1675136847569,"user_tz":-540,"elapsed":706,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["wandb.init(\n","    project=\"groom-proj3_traslation\",\n","    name = model_name\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"94d6rQZWSeLb","executionInfo":{"status":"ok","timestamp":1675136851360,"user_tz":-540,"elapsed":3813,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"a6a303d6-0f44-48d7-b587-713eacc95078"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myangdk02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/Study/Data Science/AI 자연어 처리 전문가 양성 과정 6기/Project 3/wandb/run-20230131_034726-ld2yxfco</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation/runs/ld2yxfco\" target=\"_blank\">t5-base-korean-paraphrase-finetuned-written-to-spoken</a></strong> to <a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation\" target=\"_blank\">https://wandb.ai/yangdk02/groom-proj3_traslation</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href=\"https://wandb.ai/yangdk02/groom-proj3_traslation/runs/ld2yxfco\" target=\"_blank\">https://wandb.ai/yangdk02/groom-proj3_traslation/runs/ld2yxfco</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yangdk02/groom-proj3_traslation/runs/ld2yxfco?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f93ae7c58e0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"W-Uk2GflWDPT","executionInfo":{"status":"ok","timestamp":1675136851361,"user_tz":-540,"elapsed":33,"user":{"displayName":"양다경","userId":"15714302697694853137"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    #compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySubH0zpW6N7","executionInfo":{"status":"ok","timestamp":1675136864055,"user_tz":-540,"elapsed":12725,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"d04d2597-a1e1-40b9-a634-c691615a00cc"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning https://huggingface.co/yangdk/t5-base-korean-paraphrase-finetuned-written-to-spoken into local empty directory.\n","WARNING:huggingface_hub.repository:Cloning https://huggingface.co/yangdk/t5-base-korean-paraphrase-finetuned-written-to-spoken into local empty directory.\n","Using cuda_amp half precision backend\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9BoN66vbW72h","executionInfo":{"status":"ok","timestamp":1675139007811,"user_tz":-540,"elapsed":2143780,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"d5035e04-23e7-46d0-c8be-f2bf0f5752c8"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 11012\n","  Num Epochs = 30\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 5160\n","  Number of trainable parameters = 275579136\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2408' max='5160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2408/5160 35:39 < 40:47, 1.12 it/s, Epoch 13/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.063500</td>\n","      <td>0.834316</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.841200</td>\n","      <td>0.775416</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.776900</td>\n","      <td>0.748332</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.731100</td>\n","      <td>0.732723</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.694900</td>\n","      <td>0.721960</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.666500</td>\n","      <td>0.715087</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.638600</td>\n","      <td>0.711199</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.615400</td>\n","      <td>0.707379</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.591300</td>\n","      <td>0.706000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.569300</td>\n","      <td>0.707051</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.552000</td>\n","      <td>0.706746</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.534600</td>\n","      <td>0.707443</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.519300</td>\n","      <td>0.708871</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.503100</td>\n","      <td>0.712121</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-172\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-172/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-172/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-172/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-172/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-172/special_tokens_map.json\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-344\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-344/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-344/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-344/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-344/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-344/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-516\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-516/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-516/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-516/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-516/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-516/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-688\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-688/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-688/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-688/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-688/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-688/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-860\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-860/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-860/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-860/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-860/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-860/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1032\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1032/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1032/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1032/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1032/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1032/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1204\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1204/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1204/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1204/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1204/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1204/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1376\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1376/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1376/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1376/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1376/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1376/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1720\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1720/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1720/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1720/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1720/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1720/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1892\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1892/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1892/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1892/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1892/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1892/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2064\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2064/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2064/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2064/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2064/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2064/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2236\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2236/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2236/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2236/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2236/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2236/special_tokens_map.json\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2754\n","  Batch size = 16\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Saving model checkpoint to t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2408\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2408/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2408/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2408/pytorch_model.bin\n","tokenizer config file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2408/tokenizer_config.json\n","Special tokens file saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-2408/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from t5-base-korean-paraphrase-finetuned-written-to-spoken/checkpoint-1548 (score: 0.7059997320175171).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2408, training_loss=0.6641212222584062, metrics={'train_runtime': 2143.6751, 'train_samples_per_second': 154.109, 'train_steps_per_second': 2.407, 'total_flos': 6630921152077824.0, 'train_loss': 0.6641212222584062, 'epoch': 14.0})"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["model.push_to_hub(f\"yangdk/{model_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["c4f1ef800548453a932ee7faecf966f0","f6b35a70c64d4ac3ae15073bd4959d18","ce4373a144564e07973ab93511fcafb0","cef8f5801a194bb0803d17e0117ec8e4","000fce0b61d74846b1b519f5632ea146","2800c259fb5f466ca0090c269c5e71db","e8ca64592bbf4489af9753166597c195","be5e649d9c704290a35db752a22c7f64","e0f760b126314ec7ac352e5a6bf236d1","4b9cbd23410744d8b9796068e11420c8","5956ae3ced414b4983c4f533e593bf13","ea425a07885b4ed1ba84c326c74ff59d","75f46ac5bf644c22bbc0338f3f59afd9","55fb489a7c6b4470984a4e6405351aba","06fc5ed2b2fc4d89bd3fc1880bcc1878","d26f1900cad6478d9cf98e44881a3d3a","6a17241b48894c3fbd93a6ea47ebb9d0","838f0fb02ad741f1807180d7a871d035","25186637ad16497ab7aa72e04633b1a7","f98b820c454742fe8e33af1fdec9ebf1","d33a1e79d3774473bae7f0daa3b0a0c9","df84a443233a4314b94ad237974fa09e"]},"id":"joBYM7PatTxq","executionInfo":{"status":"ok","timestamp":1675139070647,"user_tz":-540,"elapsed":62854,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"2e004291-72e4-49a8-ece7-d1b22c7c90cf"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/config.json\n","Configuration saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/generation_config.json\n","Model weights saved in t5-base-korean-paraphrase-finetuned-written-to-spoken/pytorch_model.bin\n","Uploading the following files to yangdk/t5-base-korean-paraphrase-finetuned-written-to-spoken: config.json,pytorch_model.bin,generation_config.json\n"]},{"output_type":"display_data","data":{"text/plain":["Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f1ef800548453a932ee7faecf966f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea425a07885b4ed1ba84c326c74ff59d"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/yangdk/t5-base-korean-paraphrase-finetuned-written-to-spoken/commit/de907ba7f482a3398949dbe03582e507dbfcd0f1', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='de907ba7f482a3398949dbe03582e507dbfcd0f1', pr_url=None, pr_revision=None, pr_num=None)"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["# 4️⃣ Inference"],"metadata":{"id":"1ApLl5JRYMWl"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, T5ForConditionalGeneration\n","\n","# You can of course substitute your own username and model here if you've trained and uploaded it!\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = T5ForConditionalGeneration.from_pretrained(f\"yangdk/{model_name}\")\n","model.eval()\n","model.cuda()"],"metadata":{"id":"w4sXwD5EYLGi","executionInfo":{"status":"ok","timestamp":1675139118459,"user_tz":-540,"elapsed":32341,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ee5fba13ec8a4984a2e01b23f2f4d962","e3f1db7860784c38ab075d9fdf99e4ed","18e9e3322eb34bdb8f20a8842bdc38e1","e965316bb9a64dd18913ae9c66c414f3","71e6401cf3534f6eb6809fe218950f7f","0548afe2daf9456b81503cc7a608dde5","c45b257e90e04fb5bae740ec98847a0a","785381b922514d419c99150430d3fda5","6a1cef1831d440d0ba5e55c8f93f6e1e","82583b5a59c048ea88729436d8a0d5c0","72d6fc222bc94661b0fe1d3b96680943","2b1c88953c184bc18a46b427f4bde226","36e6a057b028425d8ed425ca02f60993","ffec61b81be64ad3bf9ec5a0cca5e986","5e86bc3475a64b5a8d6204d1237d8df0","af75b0270847429a931d4aa866e7eb6a","48c3aed52197410eb75d549c02d9da2a","972285bee07f4228ab3dfbac9aefa363","e42fa79240a44e4c877dd23bd381dfb7","987a1061e3aa405aa7b87104656d9bc0","4967d1d4699c4fa5acff660dd5409c0c","7358ec6e710a46e19e3cab21d1c4af41","9d40dba04ef244b49a73ba3d0a77c8ca","fc06008184d54e9fafa80ad85af896df","af4deeac797f44f4b228ddf8234cb9b0","ccdac82e812a44218d78d522246214aa","2f65dab45e584b9892e031cee0675960","a60296d63395429786445d458adbff89","e21bb0969e1a4b02afde64b78d469ef5","97fb0f6a7ac248c2bb950822077dfcb9","c294f19d302f41d2aa2708bfc90bbc86","e9c93385fde34f51ac9078254b244b46","dd906cf5b0b0478483158f17d87c4f2a"]},"outputId":"a3cfaee7-9927-4656-9573-0d64cb68e2e4"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file spiece.model from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--lcw99--t5-base-korean-paraphrase/snapshots/ad420deab76699ab627c7d74e61d91ce74f703d5/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--lcw99--t5-base-korean-paraphrase/snapshots/ad420deab76699ab627c7d74e61d91ce74f703d5/special_tokens_map.json\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--lcw99--t5-base-korean-paraphrase/snapshots/ad420deab76699ab627c7d74e61d91ce74f703d5/tokenizer_config.json\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/796 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5fba13ec8a4984a2e01b23f2f4d962"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--yangdk--t5-base-korean-paraphrase-finetuned-written-to-spoken/snapshots/de907ba7f482a3398949dbe03582e507dbfcd0f1/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"lcw99/t5-base-korean-paraphrase\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"max_length\": 512,\n","  \"model_type\": \"t5\",\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b1c88953c184bc18a46b427f4bde226"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--yangdk--t5-base-korean-paraphrase-finetuned-written-to-spoken/snapshots/de907ba7f482a3398949dbe03582e507dbfcd0f1/pytorch_model.bin\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"max_length\": 512,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at yangdk/t5-base-korean-paraphrase-finetuned-written-to-spoken.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d40dba04ef244b49a73ba3d0a77c8ca"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--yangdk--t5-base-korean-paraphrase-finetuned-written-to-spoken/snapshots/de907ba7f482a3398949dbe03582e507dbfcd0f1/generation_config.json\n","Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"max_length\": 512,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(50358, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50358, bias=False)\n",")"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["input_text = '정기 시험이 매우 어려웠습니다.'\n","tokenized = tokenizer(input_text, return_attention_mask=False, return_token_type_ids=False, return_tensors='pt')\n","tokenized = {k: v.cuda() for k, v in tokenized.items()}\n","out = model.generate(**tokenized, max_length=128)[0, 1:-1].cpu()\n","print(tokenizer.decode(out, skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-VBBN-dKw7y","executionInfo":{"status":"ok","timestamp":1675139118460,"user_tz":-540,"elapsed":35,"user":{"displayName":"양다경","userId":"15714302697694853137"}},"outputId":"4817ed50-164d-44ae-f5aa-f028f32eb773"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"max_length\": 512,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.26.0\"\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["정기 시험은 매우 어려웠어요.\n"]}]}]}